

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Installing and Using Software on Olivia &mdash; Sigma2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/nris.css?v=69e7a171" />
      <link rel="stylesheet" type="text/css" href="../../_static/universal-navbar.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/statuspal.css" />

  
    <link rel="shortcut icon" href="../../_static/nris.ico"/>
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://siteimproveanalytics.com/js/siteanalyze_6036825.js"></script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script src="../../_static/statuspal_widget.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Job Types on Olivia" href="../../jobs/job_types/olivia_job_types.html" />
    <link rel="prev" title="Data staging and data integration between NIRD and Olivia" href="olivia-nird.html" /> 
</head>

<body class="wy-body-for-nav">
<!-- Send url to parent when displayed as iframe -->
<script>
    const valid_orign_url = "https://www.sigma2.no"
    window.addEventListener('message', function(event) {
        if (event.data === 'getDocumentationIframeUrl' && event.origin.startsWith(valid_orign_url)) {
            // path only (/path/example.html)
            const path = window.location.pathname
            // query string (including the initial ? symbol)
            const search = window.location.search
            // Returns the hash (including the initial # symbol)
            const hash = window.location.hash
            const newUrl = path + search + hash;
            event.source.postMessage(newUrl, event.origin)
        }
    })

</script>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Sigma2/NRIS documentation
              <img src="../../_static/NRIS Logo.svg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Policies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../code-of-conduct.html">Code of Conduct</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting help</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/support_line.html">Getting help</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/extended_support.html">Extended support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/how_to_write_good_support_requests.html">Writing good support requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/qa-sessions.html">Open Question &amp; Answer Sessions for All Users</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/lost_forgotten_password.html">Lost, expiring or changing passwords</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/two_factor_authentication.html">One-time-pad (OTP) / Two-factor authentication</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.sigma2.no/project-leader-handbook">Project Leader Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../training/events.html">Training events</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/notes_qa.html">Questions, Answers and Feedbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/past_training.html">An overview over training events in the past</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/videos.html">Training Video Archives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/short_instructions.html">Short Instructions Video Archives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/material.html">Training materials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/opslog.html">Status and maintenance of systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/applying_account.html">How do I get an account?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/applying_resources.html">Applying for computing and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/file_transfer.html">File transfer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/editing_files.html">Editing files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../code_development/guides/vs_code/connect_to_server.html">Connecting to a system with Visual Studio Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/ssh.html">SSH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/ssh.html#common-ssh-errors">Common SSH errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/ood.html">Open OnDemand</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/R.html">First R calculation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Files, storage and backup</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/nird_lmd.html">NIRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/clusters.html">Storage areas on HPC clusters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/quota.html">Storage quota</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/backup.html">Backup on Betzy, Fram, Saga, and NIRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/sharing_files.html">Data handling and storage policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/performance.html">Optimizing storage performance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">HPC usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migration2metacenter.html">Migration to an NRIS HPC machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../computing/responsible-use.html">Using shared resources responsibly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/overview.html">Running jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/internet-login-compute-nodes.html">Login nodes:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/internet-login-compute-nodes.html#compute-nodes">Compute nodes:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../computing/tuning-applications.html">Tuning applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../code_development/guides_llm.html">Running LLM Models in a Cluster Environment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Compute resources</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../hardware_overview.html">Overview over our machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../betzy.html">Betzy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fram.html">Fram</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../olivia.html">Olivia</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../olivia.html#the-next-generation-powerful-supercomputer-for-hpc-and-ai-applications">The next generation powerful supercomputer for HPC and AI applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../olivia.html#technical-details">Technical Details</a></li>
<li class="toctree-l2"><a class="reference internal" href="../olivia.html#getting-started-with-olivia">Getting Started with Olivia</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../olivia.html#in-depth-documentation-for-olivia">In-depth documentation for Olivia</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="overview.html">Olivia System architecture and technical specification</a></li>
<li class="toctree-l3"><a class="reference internal" href="olivia-nird.html">Data staging and data integration between NIRD and Olivia</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Installing and Using Software on Olivia</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-system">1. Module System</a></li>
<li class="toctree-l4"><a class="reference internal" href="#python-r-and-ana-conda">2. Python, R, and (Ana-)Conda</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ai-frameworks">3. AI Frameworks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../jobs/job_types/olivia_job_types.html">Job Types on Olivia</a></li>
<li class="toctree-l3"><a class="reference internal" href="ai_ml_guide.html">AI ML Guides for Olivia</a></li>
<li class="toctree-l3"><a class="reference internal" href="trouble_shooting.html">Olivia frequently asked questions (FAQ):</a></li>
<li class="toctree-l3"><a class="reference internal" href="../olivia.html#olivia-best-practices-guide-wip">Olivia Best Practices Guide (WIP)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../saga.html">Saga</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lumi.html">LUMI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Software</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../software/modulescheme.html">Software module scheme</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/installed_software.html">Installed software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/userinstallsw.html">Installing software as user</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/appguides.html">Application guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/licenses.html">Licence and access policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/eessi.html">EESSI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Additional services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../nird_archive/sandbox-user-guide.html">NIRD Research Data Archive Sandbox (NIRD RDA sandbox)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nird_archive/user-guide.html">NIRD Research Data Archive (NIRD RDA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nird_toolkit/overview.html">NIRD Toolkit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nird_service_platform/overview_nird_service_platform.html">NIRD Service Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../services/easydmp-user-documentation.html">EasyDMP User Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/course_resources.html">CRaaS - Course Resources as a Service</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code development and tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../code_development/overview.html">Code development and tutorials</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Sigma2/NRIS documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../olivia.html">Olivia</a></li>
      <li class="breadcrumb-item active">Installing and Using Software on Olivia</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="installing-and-using-software-on-olivia">
<span id="olivia-software"></span><h1><a class="toc-backref" href="#id1" role="doc-backlink">Installing and Using Software on Olivia</a><a class="headerlink" href="#installing-and-using-software-on-olivia" title="Link to this heading"></a></h1>
<nav class="contents" id="page-overview">
<p class="topic-title"><strong>Page Overview</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="#installing-and-using-software-on-olivia" id="id1">Installing and Using Software on Olivia</a></p>
<ul>
<li><p><a class="reference internal" href="#module-system" id="id2">1. Module System</a></p>
<ul>
<li><p><a class="reference internal" href="#list-available-stacks" id="id3">List Available Stacks</a></p></li>
<li><p><a class="reference internal" href="#nris-software-stacks" id="id4">NRIS Software Stacks</a></p></li>
<li><p><a class="reference internal" href="#using-the-eessi-stack" id="id5">Using the EESSI Stack</a></p></li>
<li><p><a class="reference internal" href="#gpu-enabled-software-on-eessi" id="id6">GPU-enabled Software on EESSI</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#python-r-and-ana-conda" id="id7">2. Python, R, and (Ana-)Conda</a></p>
<ul>
<li><p><a class="reference internal" href="#key-features-of-hpc-container-wrapper" id="id8">Key Features of HPC-container-wrapper</a></p></li>
<li><p><a class="reference internal" href="#creating-a-new-python-or-conda-environment" id="id9">Creating a New Python or Conda Environment</a></p></li>
<li><p><a class="reference internal" href="#modifying-an-existing-environment" id="id10">Modifying an Existing Environment</a></p></li>
<li><p><a class="reference internal" href="#tips-and-troubleshooting" id="id11">Tips and Troubleshooting</a></p></li>
<li><p><a class="reference internal" href="#example-workflow-end-to-end-conda-installation" id="id12">Example Workflow: End-to-End Conda Installation</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#ai-frameworks" id="id13">3. AI Frameworks</a></p>
<ul>
<li><p><a class="reference internal" href="#downloading-containers" id="id14">Downloading Containers</a></p></li>
<li><p><a class="reference internal" href="#running-containers" id="id15">Running Containers</a></p></li>
<li><p><a class="reference internal" href="#enabling-gpu-support" id="id16">Enabling GPU Support</a></p></li>
<li><p><a class="reference internal" href="#pytorch-example-workflow" id="id17">PyTorch Example Workflow</a></p></li>
<li><p><a class="reference internal" href="#next-steps" id="id18">Next Steps</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
<p>Olivia is a quite different machine compared to our other HPC clusters.
It built by HPE Cray computer, which provides the Cray Programming Environment (CPE) as means for advanced users to get the optimal performance when self-compiling code.
In contrast to our previous machines, Olivia has a rather large accelerator partition using Nvidia Grace-Hopper cards. These consists on the one hand of the Hopper 200 GPUs but also of the ARM based Grace CPUs, see <a class="reference internal" href="../olivia.html#olivia"><span class="std std-ref">here</span></a>.</p>
<p>We therefore decided to against trying to provide a single solution but instead offer three distinct methods of installing and loading software targeted at different user groups:</p>
<ol class="arabic simple">
<li><p>Module system providing preinstalled software and libraries.</p></li>
<li><p>HPC-container-wrapper for python and R users which replaces direct installation using Conda or pip.</p></li>
<li><p>Containers especially for PyTorch and other AI workflows.</p></li>
</ol>
<div class="admonition danger">
<p class="admonition-title">Danger</p>
<p><strong>Python, Miniconda and Ananconda User</strong></p>
<p>Python and conda installation put a lot of stress and load onto the file system.
To prevent file system slowdowns, <strong>we don’t allow native (directly with pip or conda) installations</strong>.
Instead create containerized installations using the HPC-container-wrapper or use apptainer to run containers directly.</p>
<p>Please read the sections about <a class="reference internal" href="#olivia-python"><span class="std std-ref">HPC-container-wrapper</span></a> and <a class="reference internal" href="#olivia-ai"><span class="std std-ref">AI workflows</span></a> thouroughly.</p>
<p>If you have any questions or need help, please <a class="reference internal" href="../../getting_help/support_line.html#support-line"><span class="std std-ref">contact us</span></a>.</p>
</div>
<section id="module-system">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">1. Module System</a><a class="headerlink" href="#module-system" title="Link to this heading"></a></h2>
<p>The module system provides a convenient way to access software packages and libraries that are installed and maintained specifically for the Olivia HPC cluster.
All software is compiled and optimized for Olivia’s nodes to ensure the best performance.</p>
<section id="list-available-stacks">
<h3><a class="toc-backref" href="#id3" role="doc-backlink">List Available Stacks</a><a class="headerlink" href="#list-available-stacks" title="Link to this heading"></a></h3>
<p>After logging in, no software stack is already loaded, but you easily list the available stacks with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>module<span class="w"> </span>available
</pre></div>
</div>
<p>You should see output similar to this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-----------------------------</span> <span class="o">/</span><span class="n">cluster</span><span class="o">/</span><span class="n">software</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">Core</span> <span class="o">-----------------------------</span>
   <span class="n">CrayEnv</span> <span class="p">(</span><span class="n">S</span><span class="p">)</span>    <span class="n">EESSI</span><span class="o">/</span><span class="mf">2023.06</span>    <span class="n">NRIS</span><span class="o">/</span><span class="n">CPU</span> <span class="p">(</span><span class="n">S</span><span class="p">)</span>    <span class="n">NRIS</span><span class="o">/</span><span class="n">GPU</span> <span class="p">(</span><span class="n">S</span><span class="p">)</span>    <span class="n">NRIS</span><span class="o">/</span><span class="n">Login</span> <span class="p">(</span><span class="n">S</span><span class="p">,</span><span class="n">D</span><span class="p">)</span>    <span class="n">init</span><span class="o">-</span><span class="n">NRIS</span> <span class="p">(</span><span class="n">S</span><span class="p">,</span><span class="n">L</span><span class="p">)</span>

  <span class="n">Where</span><span class="p">:</span>
   <span class="n">S</span><span class="p">:</span>  <span class="n">Module</span> <span class="ow">is</span> <span class="n">Sticky</span><span class="p">,</span> <span class="n">requires</span> <span class="o">--</span><span class="n">force</span> <span class="n">to</span> <span class="n">unload</span> <span class="ow">or</span> <span class="n">purge</span>
   <span class="n">L</span><span class="p">:</span>  <span class="n">Module</span> <span class="ow">is</span> <span class="n">loaded</span>
   <span class="n">D</span><span class="p">:</span>  <span class="n">Default</span> <span class="n">Module</span>

<span class="n">If</span> <span class="n">the</span> <span class="n">avail</span> <span class="nb">list</span> <span class="ow">is</span> <span class="n">too</span> <span class="n">long</span> <span class="n">consider</span> <span class="n">trying</span><span class="p">:</span>

<span class="s2">&quot;module --default avail&quot;</span> <span class="ow">or</span> <span class="s2">&quot;ml -d av&quot;</span> <span class="n">to</span> <span class="n">just</span> <span class="nb">list</span> <span class="n">the</span> <span class="n">default</span> <span class="n">modules</span><span class="o">.</span>
<span class="s2">&quot;module overview&quot;</span> <span class="ow">or</span> <span class="s2">&quot;ml ov&quot;</span> <span class="n">to</span> <span class="n">display</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="n">modules</span> <span class="k">for</span> <span class="n">each</span> <span class="n">name</span><span class="o">.</span>

<span class="n">Use</span> <span class="s2">&quot;module spider&quot;</span> <span class="n">to</span> <span class="n">find</span> <span class="nb">all</span> <span class="n">possible</span> <span class="n">modules</span> <span class="ow">and</span> <span class="n">extensions</span><span class="o">.</span>
<span class="n">Use</span> <span class="s2">&quot;module keyword key1 key2 ...&quot;</span> <span class="n">to</span> <span class="n">search</span> <span class="k">for</span> <span class="nb">all</span> <span class="n">possible</span> <span class="n">modules</span> <span class="n">matching</span> <span class="nb">any</span> <span class="n">of</span> <span class="n">the</span>
<span class="s2">&quot;keys&quot;</span><span class="o">.</span>

</pre></div>
</div>
<p>There are three types of stacks installed on Olivia:</p>
<ol class="arabic simple">
<li><p>NRIS software stacks providing software and libraries installed by us</p></li>
<li><p>EESSI software stack providing software and libraries curated by the European EESSI project</p></li>
<li><p>Cray programming environment providing compilers, libraries and tooling optimized for HPE Cray systems</p></li>
</ol>
</section>
<section id="nris-software-stacks">
<h3><a class="toc-backref" href="#id4" role="doc-backlink">NRIS Software Stacks</a><a class="headerlink" href="#nris-software-stacks" title="Link to this heading"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">NRIS</span></code> modules provide preinstalled software tailored for different node types:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">NRIS/CPU</span></code></strong>: Contains software packages and libraries optimized for the <strong>CPU compute nodes</strong>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">NRIS/GPU</span></code></strong>: Currently includes libraries, compilers, and tools for building software for the Grace-Hopper 200 GPUs.
In the future, this stack will also include AI frameworks such as PyTorch and TensorFlow (see <em>AI Frameworks</em> below).</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">NRIS/Login</span></code></strong>: Includes tools for pre- and post-processing data.
<strong>Note</strong>: Do not use this stack for running workflows on the compute nodes.</p></li>
</ul>
<p>To load a stack and view its available software, use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>NRIS/CPU
$<span class="w"> </span>module<span class="w"> </span>avail
</pre></div>
</div>
<section id="searching-for-modules-across-stacks">
<h4>Searching for Modules Across Stacks<a class="headerlink" href="#searching-for-modules-across-stacks" title="Link to this heading"></a></h4>
<p>You can search for a specific module across all stacks using <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">spider</span></code>. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>module<span class="w"> </span>spider<span class="w"> </span>SCOTCH
</pre></div>
</div>
<p>This will display information about the <code class="docutils literal notranslate"><span class="pre">SCOTCH</span></code> module, including available versions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-----------------------------------------------------------</span>
  <span class="n">SCOTCH</span><span class="p">:</span>
<span class="o">-----------------------------------------------------------</span>
    <span class="n">Description</span><span class="p">:</span>
      <span class="n">Software</span> <span class="n">package</span> <span class="ow">and</span> <span class="n">libraries</span> <span class="k">for</span> <span class="n">sequential</span> <span class="ow">and</span>
      <span class="n">parallel</span> <span class="n">graph</span> <span class="n">partitioning</span><span class="p">,</span> <span class="n">static</span> <span class="n">mapping</span><span class="p">,</span> <span class="ow">and</span>
      <span class="n">sparse</span> <span class="n">matrix</span> <span class="n">block</span> <span class="n">ordering</span><span class="p">,</span> <span class="ow">and</span> <span class="n">sequential</span> <span class="n">mesh</span> <span class="ow">and</span>
      <span class="n">hypergraph</span> <span class="n">partitioning</span><span class="o">.</span>

     <span class="n">Versions</span><span class="p">:</span>
        <span class="n">SCOTCH</span><span class="o">/</span><span class="mf">7.0.3</span><span class="o">-</span><span class="n">gompi</span><span class="o">-</span><span class="mi">2023</span><span class="n">a</span>
        <span class="n">SCOTCH</span><span class="o">/</span><span class="mf">7.0.4</span><span class="o">-</span><span class="n">gompi</span><span class="o">-</span><span class="mi">2023</span><span class="n">b</span>
        <span class="n">SCOTCH</span><span class="o">/</span><span class="mf">7.0.6</span><span class="o">-</span><span class="n">gompi</span><span class="o">-</span><span class="mi">2024</span><span class="n">a</span>
</pre></div>
</div>
<p>To get detailed information about a specific version, including how to load it, use the module’s full name:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>module<span class="w"> </span>spider<span class="w"> </span>SCOTCH/7.0.6-gompi-2024a
</pre></div>
</div>
<p>Similarly, for other modules like <code class="docutils literal notranslate"><span class="pre">NVHPC</span></code>, you can use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>module<span class="w"> </span>spider<span class="w"> </span>NVHPC/25.3-CUDA-12.8.0
</pre></div>
</div>
<p>This will provide details such as dependencies and additional help:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-----------------------------------------------------------</span>
  <span class="n">NVHPC</span><span class="p">:</span> <span class="n">NVHPC</span><span class="o">/</span><span class="mf">25.3</span><span class="o">-</span><span class="n">CUDA</span><span class="o">-</span><span class="mf">12.8.0</span>
<span class="o">-----------------------------------------------------------</span>
    <span class="n">Description</span><span class="p">:</span>
      <span class="n">C</span><span class="p">,</span> <span class="n">C</span><span class="o">++</span> <span class="ow">and</span> <span class="n">Fortran</span> <span class="n">compilers</span> <span class="n">included</span> <span class="k">with</span> <span class="n">the</span> <span class="n">NVIDIA</span>
      <span class="n">HPC</span> <span class="n">SDK</span> <span class="p">(</span><span class="n">previously</span><span class="p">:</span> <span class="n">PGI</span><span class="p">)</span>

    <span class="n">You</span> <span class="n">will</span> <span class="n">need</span> <span class="n">to</span> <span class="n">load</span> <span class="nb">all</span> <span class="n">module</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="n">on</span> <span class="nb">any</span> <span class="n">one</span> <span class="n">of</span> <span class="n">the</span>
    <span class="n">lines</span> <span class="n">below</span> <span class="n">before</span> <span class="n">the</span> <span class="s2">&quot;NVHPC/25.3-CUDA-12.8.0&quot;</span> <span class="n">module</span> <span class="ow">is</span>
    <span class="n">available</span> <span class="n">to</span> <span class="n">load</span><span class="o">.</span>

      <span class="n">BuildEnv</span><span class="o">/</span><span class="n">NeoverseV2</span>
      <span class="n">NRIS</span><span class="o">/</span><span class="n">GPU</span>

    <span class="n">Help</span><span class="p">:</span>
      <span class="n">Description</span>
      <span class="o">===========</span>
      <span class="n">C</span><span class="p">,</span> <span class="n">C</span><span class="o">++</span> <span class="ow">and</span> <span class="n">Fortran</span> <span class="n">compilers</span> <span class="n">included</span> <span class="k">with</span> <span class="n">the</span> <span class="n">NVIDIA</span>
      <span class="n">HPC</span> <span class="n">SDK</span> <span class="p">(</span><span class="n">previously</span><span class="p">:</span> <span class="n">PGI</span><span class="p">)</span>

      <span class="n">More</span> <span class="n">information</span>
      <span class="o">================</span>
       <span class="o">-</span> <span class="n">Homepage</span><span class="p">:</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">developer</span><span class="o">.</span><span class="n">nvidia</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">hpc</span><span class="o">-</span><span class="n">sdk</span><span class="o">/</span>
</pre></div>
</div>
</section>
</section>
<section id="using-the-eessi-stack">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">Using the EESSI Stack</a><a class="headerlink" href="#using-the-eessi-stack" title="Link to this heading"></a></h3>
<p>The EESSI (European Environment for Scientific Software Infrastructure) software stack - optimized for each supported CPU architecture - already available on Betzy, Fram, and Saga is now also available on Olivia.</p>
<p>To load the EESSI stack, simply use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>EESSI/2023.06
</pre></div>
</div>
<p>Or:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">source</span><span class="w"> </span>/cluster/installations/eessi/default/eessi_environment_variables_Olivia
$<span class="w"> </span><span class="nb">source</span><span class="w"> </span>/cvmfs/software.eessi.io/versions/2023.06/init/bash
</pre></div>
</div>
<p>The second script automatically detects the CPU microarchitecture of the current machine and selects the most appropriate pre-built software provided by EESSI. This ensures optimal performance and works seamlessly across systems with varying CPU architectures, such as those available on Olivia.</p>
<p>Once the environment is configured to access software provided by EESSI, you can interact with it using the <code class="docutils literal notranslate"><span class="pre">module</span></code> command, just like with the NRIS stacks. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>module<span class="w"> </span>avail
$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>TensorFlow/2.13.0-foss-2023a
</pre></div>
</div>
<p>The first command will list all software modules available within the EESSI stack (on the current CPU/GPU partition).
Then we load the <code class="docutils literal notranslate"><span class="pre">TensorFlow</span></code> module.</p>
<p>While EESSI provides a wide range of preinstalled software, you can <strong>build</strong> on top of EESSI either using EasyBuild through loading the EESSI-extend module:
<code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">EESSI-extend</span></code> or without EasyBuild through loading one of the available <code class="docutils literal notranslate"><span class="pre">buildenv/*</span></code> modules, for example, <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">buildenv/default-foss-2023a</span></code>
For more information see the official <a class="reference external" href="https://www.EESSI.do/docs/using_EESSI/building_on_EESSI/">EESSI documentation</a>.</p>
</section>
<section id="gpu-enabled-software-on-eessi">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">GPU-enabled Software on EESSI</a><a class="headerlink" href="#gpu-enabled-software-on-eessi" title="Link to this heading"></a></h3>
<p>The official EESSI stack contains already some modules of popular software like GROMACS, but many are also still missing.</p>
<p>To get you started more quickly, we have added some GPU-enabled software on Olivia which are not yet provided by <a class="reference external" href="https://www.eessi.io/docs">EESSI</a> or supported by <a class="reference external" href="https://easybuild.io/">EasyBuild</a>.</p>
<p><strong>Note</strong>: If your job requires the use of MPI, please ensure you use <code class="docutils literal notranslate"><span class="pre">srun</span></code> for proper integration.
Sample job script using <code class="docutils literal notranslate"><span class="pre">OSU-Micro-Benchmarks/7.2-gompi-2023b</span></code> from the EESSI stack:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash -e</span>
<span class="c1">#SBATCH --job-name=Sample</span>
<span class="c1">#SBATCH --account=nnXXXX</span>
<span class="c1">#SBATCH --time=00:05:00</span>
<span class="c1">#SBATCH --partition=normal</span>
<span class="c1">#SBATCH --nodes=2</span>
<span class="c1">#SBATCH --ntasks-per-node=1</span>
<span class="c1">#SBATCH --mem-per-cpu=10G</span>

module<span class="w"> </span>load<span class="w"> </span>EESSI/2023.06
module<span class="w"> </span>load<span class="w"> </span>OSU-Micro-Benchmarks/7.2-gompi-2023b

srun<span class="w"> </span>osu_bw
</pre></div>
</div>
</section>
</section>
<section id="python-r-and-ana-conda">
<span id="olivia-python"></span><h2><a class="toc-backref" href="#id7" role="doc-backlink">2. Python, R, and (Ana-)Conda</a><a class="headerlink" href="#python-r-and-ana-conda" title="Link to this heading"></a></h2>
<p>Python and R are widely used in scientific computing, but they were originally designed for personal computers rather than
high-performance computing (HPC) environments. These languages often involve installations with a large number of small
files—Python environments, for example, can easily consist of tens or even hundreds of thousands of files. This can strain
the file system, leading to poor performance and a sluggish user experience.</p>
<p>To address this, Olivia uses the <a class="reference external" href="https://github.com/CSCfi/hpc-container-wrapper/"><em>HPC-container-wrapper</em></a>, a tool designed to encapsulate
installations within containers optimized for HPC systems. This tool wraps Python or Conda environments inside containers,
significantly reducing the number of files visible to the file system. It also generates executables, allowing you to run commands
like <code class="docutils literal notranslate"><span class="pre">python</span></code> seamlessly, without needing to interact directly with the container. This approach minimizes file system load while
maintaining ease of use.</p>
<section id="key-features-of-hpc-container-wrapper">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Key Features of HPC-container-wrapper</a><a class="headerlink" href="#key-features-of-hpc-container-wrapper" title="Link to this heading"></a></h3>
<p>The HPC-container-wrapper supports wrapping:</p>
<ul class="simple">
<li><p><strong>Conda installations</strong>: Based on a <a class="reference external" href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#sharing-an-environment">Conda environment file</a>.</p></li>
<li><p><strong>Pip installations</strong>: Based on a <a class="reference external" href="https://pip.pypa.io/en/latest/reference/requirements-file-format/">pip requirements.txt file</a>.</p></li>
<li><p><strong>Existing installations on the file system</strong>: To reduce I/O load and improve startup times.</p></li>
<li><p><strong>Existing Singularity/Apptainer containers</strong>: To hide the need for using the container runtime from the user.</p></li>
</ul>
</section>
<section id="creating-a-new-python-or-conda-environment">
<h3><a class="toc-backref" href="#id9" role="doc-backlink">Creating a New Python or Conda Environment</a><a class="headerlink" href="#creating-a-new-python-or-conda-environment" title="Link to this heading"></a></h3>
<p>To create a new Python or Conda environment on Olivia, follow these steps:</p>
<ol class="arabic">
<li><p><strong>Load the necessary modules and activate internet access from the compute nodes</strong>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">http_proxy</span><span class="o">=</span>http://10.63.2.48:3128/
$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">https_proxy</span><span class="o">=</span>http://10.63.2.48:3128/
$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>NRIS/CPU
$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>hpc-container-wrapper
</pre></div>
</div>
</li>
<li><p><strong>Prepare your environment file</strong>:</p>
<ul>
<li><p>For <strong>pip</strong>, create a <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> file listing the packages you need. For example:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>numpy==1.23.5
scipy==1.10.1
matplotlib
</pre></div>
</div>
</li>
<li><p>For <strong>Conda</strong>, create an <code class="docutils literal notranslate"><span class="pre">env.yml</span></code> file. For example:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">channels</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">conda-forge</span>
<span class="nt">dependencies</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">python=3.10</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">numpy</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pandas</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">matplotlib</span>
</pre></div>
</div>
</li>
</ul>
<p>Alternatively, you can export an environment from an existing setup (e.g., on your laptop or another cluster):</p>
</li>
</ol>
<ul>
<li><p>Export a Conda environment:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>conda<span class="w"> </span>env<span class="w"> </span><span class="nb">export</span><span class="w"> </span>-n<span class="w"> </span>&lt;env_name&gt;<span class="w"> </span>&gt;<span class="w"> </span>env.yml
</pre></div>
</div>
<p><em>Note</em>: On Windows or macOS, add the <code class="docutils literal notranslate"><span class="pre">--from-history</span></code> flag to avoid including platform-specific dependencies.</p>
</li>
<li><p>Export a pip environment:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>pip<span class="w"> </span>freeze<span class="w"> </span>&gt;<span class="w"> </span>requirements.txt
</pre></div>
</div>
</li>
</ul>
<ol class="arabic" start="3">
<li><p><strong>Build the environment</strong>:</p>
<ul>
<li><p>For <strong>pip</strong>, use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>pip-containerize<span class="w"> </span>new<span class="w"> </span>--prefix<span class="w"> </span>&lt;install_dir&gt;<span class="w"> </span>--slim<span class="w"> </span>requirements.txt
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">--slim</span></code> argument uses a pre-built minimal Python container with a newer Python version as a base.
Without <code class="docutils literal notranslate"><span class="pre">--slim</span></code>, the host system is fully available, but this may include unnecessary system installations.</p>
</li>
<li><p>For <strong>Conda</strong>, use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>conda-containerize<span class="w"> </span>new<span class="w"> </span>--prefix<span class="w"> </span>&lt;install_dir&gt;<span class="w"> </span>env.yml
</pre></div>
</div>
<p>If you also need to install additional pip packages, you can combine both files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>conda-containerize<span class="w"> </span>new<span class="w"> </span>-r<span class="w"> </span>requirements.txt<span class="w"> </span>--prefix<span class="w"> </span>&lt;install_dir&gt;<span class="w"> </span>env.yml
</pre></div>
</div>
</li>
</ul>
</li>
<li><p><strong>Add the environment to your PATH</strong>:</p>
<p>After the installation is complete, add the <code class="docutils literal notranslate"><span class="pre">bin</span></code> directory of your environment to your <code class="docutils literal notranslate"><span class="pre">PATH</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;&lt;install_dir&gt;/bin:</span><span class="nv">$PATH</span><span class="s2">&quot;</span>
</pre></div>
</div>
<p>You can now call <code class="docutils literal notranslate"><span class="pre">python</span></code> or any other executables installed in the environment as if the environment were activated.</p>
</li>
</ol>
</section>
<section id="modifying-an-existing-environment">
<h3><a class="toc-backref" href="#id10" role="doc-backlink">Modifying an Existing Environment</a><a class="headerlink" href="#modifying-an-existing-environment" title="Link to this heading"></a></h3>
<p>Since the environment is wrapped inside a container, direct modifications are not possible. However, you can update the environment using the <code class="docutils literal notranslate"><span class="pre">update</span></code> keyword along with a post-installation script. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>conda-containerize<span class="w"> </span>update<span class="w"> </span>&lt;install_dir&gt;<span class="w"> </span>--post-install<span class="w"> </span>&lt;script.sh&gt;
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">&lt;script.sh&gt;</span></code> file might contain commands like:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>conda<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>seaborn
$<span class="w"> </span>conda<span class="w"> </span>remove<span class="w"> </span>-y<span class="w"> </span>pyyaml
$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>requests
</pre></div>
</div>
</section>
<section id="tips-and-troubleshooting">
<h3><a class="toc-backref" href="#id11" role="doc-backlink">Tips and Troubleshooting</a><a class="headerlink" href="#tips-and-troubleshooting" title="Link to this heading"></a></h3>
<ul>
<li><p><strong>Exporting environments</strong>: If you encounter issues with version conflicts, you can remove version specifications from your environment file using a simple <code class="docutils literal notranslate"><span class="pre">sed</span></code> command. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>sed<span class="w"> </span><span class="s1">&#39;/==/s/==.*//&#39;</span><span class="w"> </span>requirements.txt<span class="w"> </span>&gt;<span class="w"> </span>requirements_versionless.txt<span class="w">  </span><span class="c1"># Works for pip files</span>
$<span class="w"> </span>sed<span class="w"> </span><span class="s1">&#39;/=/s/=.*//&#39;</span><span class="w"> </span>env.yml<span class="w"> </span>&gt;<span class="w"> </span>env_versionless.yml<span class="w">  </span><span class="c1"># Works for conda files</span>
</pre></div>
</div>
</li>
<li><p><strong>Using Mamba</strong>: For faster Conda installations, you can enable <a class="reference external" href="https://github.com/mamba-org/mamba">Mamba</a> by adding the <code class="docutils literal notranslate"><span class="pre">--mamba</span></code> flag:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>conda-containerize<span class="w"> </span>new<span class="w"> </span>--mamba<span class="w"> </span>--prefix<span class="w"> </span>&lt;install_dir&gt;<span class="w"> </span>env.yml
</pre></div>
</div>
</li>
<li><p><strong>Limitations</strong>: Be aware of the <a class="reference external" href="https://github.com/CSCfi/hpc-container-wrapper#limitations">limitations of HPC-container-wrapper</a>, such as its experimental status and potential issues with advanced features.</p></li>
</ul>
</section>
<section id="example-workflow-end-to-end-conda-installation">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Example Workflow: End-to-End Conda Installation</a><a class="headerlink" href="#example-workflow-end-to-end-conda-installation" title="Link to this heading"></a></h3>
<ol class="arabic">
<li><p>Create an <code class="docutils literal notranslate"><span class="pre">env.yml</span></code> file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">channels</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">conda-forge</span>
<span class="nt">dependencies</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">python=3.9</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">numpy</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">scipy</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">matplotlib</span>
</pre></div>
</div>
</li>
<li><p>Build the environment:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>NRIS/CPU<span class="w"> </span>hpc-container-wrapper
$<span class="w"> </span>conda-containerize<span class="w"> </span>new<span class="w"> </span>--prefix<span class="w"> </span>MyEnv<span class="w"> </span>env.yml
</pre></div>
</div>
</li>
<li><p>Add the environment to your <code class="docutils literal notranslate"><span class="pre">PATH</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$PWD</span><span class="s2">/MyEnv/bin:</span><span class="nv">$PATH</span><span class="s2">&quot;</span>
</pre></div>
</div>
</li>
<li><p>Use the environment:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python<span class="w"> </span>--version
Python<span class="w"> </span><span class="m">3</span>.9.0
</pre></div>
</div>
</li>
</ol>
<p>For more examples and advanced usage, see the <a class="reference external" href="https://github.com/CSCfi/hpc-container-wrapper">HPC-container-wrapper GitHub repository</a> and check the <a class="reference external" href="https://docs.lumi-supercomputer.eu/software/installing/container-wrapper/#wrapping-a-plain-pip-installation">documentation page of CSC about HPC-container-wrapper</a>.</p>
</section>
</section>
<section id="ai-frameworks">
<span id="olivia-ai"></span><h2><a class="toc-backref" href="#id13" role="doc-backlink">3. AI Frameworks</a><a class="headerlink" href="#ai-frameworks" title="Link to this heading"></a></h2>
<p>For AI workflows based on popular frameworks like PyTorch, JAX, or TensorFlow, we aim to deliver optimal performance by utilizing containers provided by <a class="reference external" href="https://catalog.ngc.nvidia.com/containers">NVIDIA</a>. These containers are specifically optimized for GPU workloads, ensuring excellent performance while remaining relatively straightforward to use.</p>
<div class="admonition danger">
<p class="admonition-title">Danger</p>
<p>Please <strong>do not install PyTorch directly via pip or conda</strong> as this puts a lot of stress on the file system.</p>
<p>Instead use the containers presented below or the module we will provide soon (documentation on that will follow).</p>
</div>
<section id="downloading-containers">
<h3><a class="toc-backref" href="#id14" role="doc-backlink">Downloading Containers</a><a class="headerlink" href="#downloading-containers" title="Link to this heading"></a></h3>
<p>You can use pre-built containers or download and convert your own. Here are the options:</p>
<ol class="arabic">
<li><p><strong>Pre-Built Containers</strong>:
Some NVIDIA containers are already available in the Apptainer image format (<code class="docutils literal notranslate"><span class="pre">.sif</span></code>) under:
<code class="docutils literal notranslate"><span class="pre">/cluster/work/support/container</span></code>.</p></li>
<li><p><strong>Downloading Your Own Containers</strong>:</p>
<p>You can download containers from sources like the <a class="reference external" href="https://catalog.ngc.nvidia.com/containers">NVIDIA NCC catalogue</a> or <a class="reference external" href="https://hub.docker.com/">Docker Hub</a>. Use the following command to download and convert a container into the Apptainer format:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>apptainer<span class="w"> </span>pull<span class="w"> </span>--arch<span class="w"> </span>ARCHITECTURE<span class="w"> </span>--disable-cache<span class="w"> </span>docker://&lt;docker_image_url&gt;
</pre></div>
</div>
<p>By default this command downloads the container for the CPU architecture of the nodes you are running on. That means that you have to specify <code class="docutils literal notranslate"><span class="pre">--arch</span> <span class="pre">arm64</span></code> if you download the container from the login nodes but want to run the container on the accelerator/GPU nodes.</p>
<p>For example, to download and convert the latest NVIDIA PyTorch container to run on the GPU nodes (that use ARM CPUs):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>apptainer<span class="w"> </span>pull<span class="w"> </span>--arch<span class="w"> </span>arm64<span class="w"> </span>--disable-cache<span class="w"> </span>docker://nvcr.io/nvidia/pytorch:25.09-py3
</pre></div>
</div>
<p>For more options, check the Apptainer build help:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>apptainer<span class="w"> </span>pull<span class="w"> </span>--help
</pre></div>
</div>
</li>
</ol>
<section id="important-notes">
<h4>Important Notes<a class="headerlink" href="#important-notes" title="Link to this heading"></a></h4>
<ul>
<li><p><strong>Building Your Own Containers:</strong>
Currently it is only possible to build containers from definition files that don’t require root privileges inside the container. We are working on enabling some version of fakeroot to enable most builds in the future.</p></li>
<li><p><strong>Running on GPU Nodes</strong>:
If you plan to run these containers on GPU nodes, ensure that you download the container from a GPU node. This can be done either via a job script or an interactive job. This ensures that the container is built for the correct architecture (e.g., ARM64).
For details on accessing internet resources from compute nodes, see <a class="reference internal" href="../../olivia_pilot_period_docs/olivia_pilot_main.html#olivia-internet-proxies"><span class="std std-ref">this section</span></a>.</p></li>
<li><p><strong>Managing Cache</strong>:
By default, Apptainer stores its cache in your home directory, which may lead to <code class="docutils literal notranslate"><span class="pre">disk</span> <span class="pre">quota</span> <span class="pre">exceeded</span></code> errors. To avoid this, use `–disable-cache* or set the cache directory to your project work area:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">APPTAINER_CACHEDIR</span><span class="o">=</span>/cluster/work/projects/&lt;project_number&gt;/singularity
</pre></div>
</div>
</li>
</ul>
</section>
</section>
<section id="running-containers">
<h3><a class="toc-backref" href="#id15" role="doc-backlink">Running Containers</a><a class="headerlink" href="#running-containers" title="Link to this heading"></a></h3>
<p>Apptainer provides several ways to run containers, depending on your needs:</p>
<ol class="arabic">
<li><p><strong>Run the Default Command</strong>:
Use <code class="docutils literal notranslate"><span class="pre">apptainer</span> <span class="pre">run</span></code> to execute the default command specified in the container setup. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>apptainer<span class="w"> </span>run<span class="w"> </span>&lt;image_path&gt;.sif<span class="w"> </span>&lt;extra_parameters&gt;
</pre></div>
</div>
<p><em>Example</em>: Running a containerized application with its default configuration.</p>
</li>
<li><p><strong>Execute Arbitrary Commands</strong>:
Use <code class="docutils literal notranslate"><span class="pre">apptainer</span> <span class="pre">exec</span></code> to run specific commands available inside the container. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>apptainer<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>&lt;image_path&gt;.sif<span class="w"> </span>&lt;command&gt;<span class="w"> </span>&lt;extra_parameters&gt;
</pre></div>
</div>
<p><em>Example</em>: Running a Python script inside the container.</p>
</li>
<li><p><strong>Interactive Shell</strong>:
Use <code class="docutils literal notranslate"><span class="pre">apptainer</span> <span class="pre">shell</span></code> to start an interactive shell session inside the container. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>apptainer<span class="w"> </span>shell<span class="w"> </span>&lt;image_path&gt;.sif<span class="w"> </span>&lt;extra_parameters&gt;
</pre></div>
</div>
<p><em>Example</em>: Exploring the container environment or debugging.</p>
</li>
<li><p><strong>Job Script Setup for multi GPU (single node/multi node)</strong>:</p>
<p>While experimenting, we encountered cases where the <code class="docutils literal notranslate"><span class="pre">torchrun</span></code> was not recognized unless its full path was explicitly specified. We can set the path to the <code class="docutils literal notranslate"><span class="pre">torchrun</span></code> as <code class="docutils literal notranslate"><span class="pre">TORCHRUN_PATH=&quot;/usr/local/bin/torchrun</span></code>, then bind it with the apptainer exec command as <code class="docutils literal notranslate"><span class="pre">apptainer</span> <span class="pre">exec</span> <span class="pre">--nv</span> <span class="pre">--bind</span>&#160; <span class="pre">$TORCHRUN_PATH</span> <span class="pre">./your_script.py</span></code>.</p>
<p>Moreover , if we need GPUs across multiple nodes, we have to take into consideration that some of the framework like Libfabric might not be installed on the container. So, we need to explicitly bind it so that our container could be use to run on multiple nodes.</p>
<p>In our host system, we identified that the libfabric is available at this location <code class="docutils literal notranslate"><span class="pre">/opt/cray/libfabric/1.22.0/lib64</span></code> . The code written below on the job script will add <code class="docutils literal notranslate"><span class="pre">--bind</span> <span class="pre">/opt/cray/libfabric/1.22.0/lib64:/usr/lib64</span></code> to the apptainer command which ensures that the libfabric libraries from the host system are available inside the container at `/usr/lib64``</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Bind libfabric (adjust the path based on your host system)</span>
<span class="nv">LIBFABRIC_PATH</span><span class="o">=</span><span class="s2">&quot;/opt/cray/libfabric/1.22.0/lib64&quot;</span>

<span class="c1"># Explicitly specify the full path to torchrun</span>
<span class="nv">TORCHRUN_PATH</span><span class="o">=</span><span class="s2">&quot;/usr/local/bin/torchrun&quot;</span>

<span class="c1"># Run the training script with torchrun inside the container</span>
srun<span class="w"> </span>apptainer<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>--bind<span class="w">  </span><span class="nv">$LIBFABRIC_PATH</span>:/usr/lib64<span class="w">  </span><span class="nv">$TORCHRUN_PATH</span><span class="w"> </span>--nnodes<span class="o">=</span><span class="nv">$SLURM_JOB_NUM_NODES</span><span class="w"> </span>--nproc_per_node<span class="o">=</span><span class="nv">$SLURM_GPUS_ON_NODE</span><span class="w"> </span>--rdzv_id<span class="o">=</span><span class="nv">$RANDOM</span><span class="w"> </span>.....
</pre></div>
</div>
</li>
</ol>
</section>
<section id="enabling-gpu-support">
<h3><a class="toc-backref" href="#id16" role="doc-backlink">Enabling GPU Support</a><a class="headerlink" href="#enabling-gpu-support" title="Link to this heading"></a></h3>
<p>To enable GPU support inside the container, add the <code class="docutils literal notranslate"><span class="pre">--nv</span></code> flag to your Apptainer command. This ensures that the container has access to the GPU resources. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>apptainer<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>/cluster/work/support/container/pytorch_nvidia_25.06_arm64.sif<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import torch; print(torch.cuda.is_available()); print(torch.cuda.device_count())&#39;</span>
</pre></div>
</div>
<p>This command checks if GPUs are available and prints the number of GPUs detected inside the container.</p>
</section>
<section id="pytorch-example-workflow">
<h3><a class="toc-backref" href="#id17" role="doc-backlink">PyTorch Example Workflow</a><a class="headerlink" href="#pytorch-example-workflow" title="Link to this heading"></a></h3>
<p>We have provided a comprehensive example on how to run PyTorch in a container on <a class="reference internal" href="../../code_development/guides/olivia_pytorch.html#pytorch-olivia"><span class="std std-ref">this page</span></a>.</p>
</section>
<section id="next-steps">
<h3><a class="toc-backref" href="#id18" role="doc-backlink">Next Steps</a><a class="headerlink" href="#next-steps" title="Link to this heading"></a></h3>
<p>Currently, you need to run these containers directly using Apptainer. However, we are working on simplifying the experience by integrating these tools into the module system. This will allow you to:</p>
<ul class="simple">
<li><p>Load a module that provides executables like <code class="docutils literal notranslate"><span class="pre">python</span></code> and <code class="docutils literal notranslate"><span class="pre">torch</span></code>, eliminating the need to interact with the containers directly.</p></li>
<li><p>Seamlessly use AI frameworks without worrying about container management.</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="olivia-nird.html" class="btn btn-neutral float-left" title="Data staging and data integration between NIRD and Olivia" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../jobs/job_types/olivia_job_types.html" class="btn btn-neutral float-right" title="Job Types on Olivia" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Sigma2/NRIS. Text shared under CC-BY 4.0 license.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>