

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Example VTune Analysis &mdash; Sigma2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/nris.css?v=69e7a171" />
      <link rel="stylesheet" type="text/css" href="../../_static/universal-navbar.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/statuspal.css" />

  
    <link rel="shortcut icon" href="../../_static/nris.ico"/>
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://siteimproveanalytics.com/js/siteanalyze_6036825.js"></script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script src="../../_static/statuspal_widget.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">
<!-- Send url to parent when displayed as iframe -->
<script>
    const valid_orign_url = "https://www.sigma2.no"
    window.addEventListener('message', function(event) {
        if (event.data === 'getDocumentationIframeUrl' && event.origin.startsWith(valid_orign_url)) {
            // path only (/path/example.html)
            const path = window.location.pathname
            // query string (including the initial ? symbol)
            const search = window.location.search
            // Returns the hash (including the initial # symbol)
            const hash = window.location.hash
            const newUrl = path + search + hash;
            event.source.postMessage(newUrl, event.origin)
        }
    })

</script>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Sigma2/NRIS documentation
              <img src="../../_static/NRIS Logo.svg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Policies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../code-of-conduct.html">Code of Conduct</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting help</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/support_line.html">Getting help</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/extended_support.html">Extended support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/how_to_write_good_support_requests.html">Writing good support requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/qa-sessions.html">Open Question &amp; Answer Sessions for All Users</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/lost_forgotten_password.html">Lost, expiring or changing passwords</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/two_factor_authentication.html">One-time-pad (OTP) / Two-factor authentication</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.sigma2.no/project-leader-handbook">Project Leader Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../training/events.html">Training events</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/notes_qa.html">Questions, Answers and Feedbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/past_training.html">An overview over training events in the past</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/videos.html">Training Video Archives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/short_instructions.html">Short Instructions Video Archives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/material.html">Training materials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/opslog.html">Status and maintenance of systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/applying_account.html">How do I get an account?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/applying_resources.html">Applying for computing and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/file_transfer.html">File transfer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/editing_files.html">Editing files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/vs_code/connect_to_server.html">Connecting to a system with Visual Studio Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/ssh.html">SSH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/ssh.html#common-ssh-errors">Common SSH errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/ood.html">Open OnDemand</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/R.html">First R calculation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Files, storage and backup</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/nird_lmd.html">NIRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/clusters.html">Storage areas on HPC clusters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/quota.html">Storage quota</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/backup.html">Backup on Betzy, Fram, Saga, and NIRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/sharing_files.html">Data handling and storage policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/performance.html">Optimizing storage performance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">HPC usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/migration2metacenter.html">Migration to an NRIS HPC machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../computing/responsible-use.html">Using shared resources responsibly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/overview.html">Running jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/internet-login-compute-nodes.html">Login nodes:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/internet-login-compute-nodes.html#compute-nodes">Compute nodes:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../computing/tuning-applications.html">Tuning applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides_llm.html">Running LLM Models in a Cluster Environment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Compute resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/hardware_overview.html">Overview over our machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/betzy.html">Betzy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/fram.html">Fram</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/olivia.html">Olivia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/saga.html">Saga</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/lumi.html">LUMI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Software</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../software/modulescheme.html">Software module scheme</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/installed_software.html">Installed software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/userinstallsw.html">Installing software as user</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/appguides.html">Application guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/licenses.html">Licence and access policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/eessi.html">EESSI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Additional services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../nird_archive/sandbox-user-guide.html">NIRD Research Data Archive Sandbox (NIRD RDA sandbox)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nird_archive/user-guide.html">NIRD Research Data Archive (NIRD RDA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nird_toolkit/overview.html">NIRD Toolkit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nird_service_platform/overview_nird_service_platform.html">NIRD Service Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../services/easydmp-user-documentation.html">EasyDMP User Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/course_resources.html">CRaaS - Course Resources as a Service</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code development and tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Code development and tutorials</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Sigma2/NRIS documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Example VTune Analysis</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="example-vtune-analysis">
<h1>Example VTune Analysis<a class="headerlink" href="#example-vtune-analysis" title="Link to this heading"></a></h1>
<p>As an example we use VTune Amplifier to analyze the performance of the
original, and the optimized software package ART - a 3D radiative
transfer solver developed within the <a class="reference external" href="https://www.mn.uio.no/astro/english/research/projects/solaralma/">SolarALMA
project</a>. The
code is written in C++ and consists of two major computational
parts:</p>
<ul class="simple">
<li><p>An equation of state (EOS) solver, which - based on various types of
input data - computes electron density, gas pressure, and
density.</p></li>
<li><p>A nonlinear solver for radiative transfer (RT). This code is based on
a FORTRAN code from 1970 by Robert Kurucz.</p></li>
</ul>
<p>Input data is read from HDF5 files and composed into a set of 3D
Cartesian grids. The two kernels described above are executed
independently for each grid point, with no communication required by
the neighbor cells. In this sense the code is trivially
parallelizable and to find opportunities for optimization we look at
the per-core (call it “sequential”) performance. The optimization
effort has been done within the PRACE Preparatory Access project type
D. For more details about the optimizatoin techniques <a class="reference external" href="https://doi.org/10.5281/zenodo.2633704">consult the
white paper.</a></p>
<section id="using-vtune-on-fram">
<h2>Using VTune on Fram<a class="headerlink" href="#using-vtune-on-fram" title="Link to this heading"></a></h2>
<p>First, to use VTune on Fram you need to load the corresponding
software module <code class="docutils literal notranslate"><span class="pre">VTune</span></code>. To list the available versions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ml avail VTune

   VTune/2017_update1    VTune/2018_update1    VTune/2018_update3
</pre></div>
</div>
<p>Then load the desired (newest) version</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ml load VTune/2018_update3
</pre></div>
</div>
<p>To gather information about a code’s performance one needs to execute
the code using the <code class="docutils literal notranslate"><span class="pre">amplxe-cl</span></code>
command. Depending
on the needs, <code class="docutils literal notranslate"><span class="pre">amplxe-cl</span></code> can gather all sorts of performance statistics: FPU
utilization, usage of vector (SIMD) AVX insturctions, instructions per
clock, memory bandwidth, cache utilization, threading level, etc. For
example, to collect general information about the most time-consuming
parts of the code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ amplxe-cl -collect hotspots ./your-program your-arguments
</pre></div>
</div>
<p>For a complete list of analysis modes please consult the <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html">VTune
documentation</a>. A
useful set of performance metrics is gathered by the
<code class="docutils literal notranslate"><span class="pre">hрc-performance</span></code> analysis, which can help to identify opportunities
to optimize CPU, memory, and vectorization level:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ amplxe-cl -collect hpc-performance ./your-program your-arguments
</pre></div>
</div>
<p>A detailed description and the available options for each profiling
mode can be obtained as follows</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ amplxe-cl -help collect hpc-performance

[...]

 To modify the analysis type, use the configuration options (knobs) as
 follows:
 -collect hpc-performance -knob &lt;knobName&gt;=&lt;knobValue&gt;
 Multiple -knob options are allowed and can be followed by additional collect
 action options, as well as global options, if needed.

sampling-interval
[...]

enable-stack-collection
[...]

collect-memory-bandwidth
[...]

dram-bandwidth-limits
[...]

analyze-openmp
[...]
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">enable-stack-collection</span></code> knob, disabled by default, provides detailed
caller / callee information for each profiled function. It can be very
useful, but might introduce some overhead. We will use it in the
following example.</p>
<p>Collected performance statistics are saved in a subdirectory, by
default in the directory you are running from. For the above example
the results are stored in <code class="docutils literal notranslate"><span class="pre">r000hpc/</span></code>. They can then be compressed and
moved to, e.g., a desktop computer, or they can be analyzed on one of
the Fram login nodes using the VTune Amplifier GUI:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh -Y fram.sigma2.no
$ ml load VTune/2018_update3
$ amplxe-gui
</pre></div>
</div>
<p>Note that running the GUI directly on Fram migh feel sluggish depending
on your network connection.</p>
</section>
<section id="vtune-analysis">
<h2>VTune analysis<a class="headerlink" href="#vtune-analysis" title="Link to this heading"></a></h2>
<p>The performance characteristics of the original code are obtained as
follows</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">amplxe</span><span class="o">-</span><span class="n">cl</span> <span class="o">-</span><span class="n">collect</span> <span class="n">hpc</span><span class="o">-</span><span class="n">performance</span> <span class="o">-</span><span class="n">knob</span> <span class="n">enable</span><span class="o">-</span><span class="n">stack</span><span class="o">-</span><span class="n">collection</span><span class="o">=</span><span class="n">true</span> <span class="o">-</span><span class="n">knob</span> <span class="n">collect</span><span class="o">-</span><span class="n">memory</span><span class="o">-</span><span class="n">bandwidth</span><span class="o">=</span><span class="n">false</span> <span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="mi">1</span> <span class="o">./</span><span class="n">ART</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
<p>Since we are interested in the “sequential” (per-core) performance, we
only analyze a single MPI rank. The stack collection is enabled. Once
the sampling results are opened in the VTune Amplifier GUI, the
performance summary is presented:</p>
<p><img alt="VTune Summary" src="../../_images/vtune_summary.png" /></p>
<p>The CPU Utilization section shows the total percentage of all
available cores used. Since a single ART process was executed, this
metric is very low (1 out of 64 logical cores are used), but that is
expected. The memory statistics show that ART is compute bound: there
is almost no references to the global memory (DRAM bound 0%). Also the
caches are not very busy. It is clear that most of the run time goes
into CPU instructions.</p>
<p>The FPU utilization report is hence the most interesting one in this
case. It reveals that 90% of the floating point instructions are scalar, i.e.,
the vector units (AVX) are mostly unused. Looking at the top most busy
functions it becomes clear that the time is spent in calls to <code class="docutils literal notranslate"><span class="pre">libm</span></code>
<code class="docutils literal notranslate"><span class="pre">exp</span></code> and <code class="docutils literal notranslate"><span class="pre">log</span></code>.</p>
<p>A closer look at the Bottom-up section of the performance report
reveals the heaviest parts of the code.</p>
<p><img alt="VTune Bottom-up" src="../../_images/vtune_bottomup.png" /></p>
<p>This confirms the previous finding (and adds <code class="docutils literal notranslate"><span class="pre">pow</span></code> to the list of
computationally heavy functions). From the above reports we can
roughly sketch the optimization directions:</p>
<ul class="simple">
<li><p>Re-write the code such that the vectorized math library is used for
<code class="docutils literal notranslate"><span class="pre">exp,</span> <span class="pre">log,</span> <span class="pre">pow</span></code> calls</p></li>
<li><p>Concentrate on the heaviest functions from the Bottom-up list</p></li>
</ul>
</section>
<section id="the-optimized-code">
<h2>The optimized code<a class="headerlink" href="#the-optimized-code" title="Link to this heading"></a></h2>
<p>Both GCC and ICC provide an interface to a vectorized math library with
platform-optimized implementations of amongst others
<code class="docutils literal notranslate"><span class="pre">exp,pow,log</span></code>. Intel compiler uses
its own Short Vector Math Library (SVML). The library comes together
with the compiler installation, and there is nothing system-specific
that needs to be done to use it. GCC on the other hand relies on
<code class="docutils literal notranslate"><span class="pre">libmvec</span></code>, which is part of Glibc version 2.22 and higher. This means
that on systems with an older version of Glibc the vectorized math
library is not readily available, regardless of the GCC version. This
is a practical problem, because OS vendors often lag a few years when
it comes to Glibc (e.g., Centos 7.5 comes with version 2.17 released
in the end of 2012). However, it is possible to install a custom Glibc
as a module and use it for user’s code.</p>
<p>As noted in the <a class="reference external" href="https://software.intel.com/en-us/node/524289">documentation of
SVML</a> the vectorized
math library differs from the scalar functions in accuracy.  Scalar
implementations are not the same as the vectorized ones with vector
width of 1. Instead, they follow strict floating-point arithmetic and
are more computationally demanding. GCC is by default conservative
wrt. the floating-point optimizations: vectorized math library is only
enabled with the <code class="docutils literal notranslate"><span class="pre">-ffast-math</span></code> compiletime option. ICC by default uses
relaxed settings (<code class="docutils literal notranslate"><span class="pre">-fp-model</span> <span class="pre">fast=1</span></code>), which allow the compiler to
make calls to low accuracy SVML functions. In addition, SVML also
provides higher accuracy vectorized functions (<code class="docutils literal notranslate"><span class="pre">-fp-model</span> <span class="pre">precise</span></code>).
Vectorization of libm calls can be prohibited with <code class="docutils literal notranslate"><span class="pre">-fp-model</span> <span class="pre">strict</span></code>. With ART the high accuracy is not required, hence we compile
the code with the most relaxed settings.</p>
<p>Vectorization of the code has been performed using <code class="docutils literal notranslate"><span class="pre">#pragma</span> <span class="pre">simd</span></code>
defined by the OpenMP standard. All the heaviest ART functions, and
all floating-point intensive loops have been vectorized using this
method, and VTune was used throughout the process to find new
bottlenecks once the existing ones have been optimized. Below is the
final VTune report of the optimized code compiled using the GCC 8
compiler:</p>
<p><img alt="VTune Summary - Optimized GCC" src="../../_images/vtune_opt_gcc.png" /></p>
<p>and using the Intel 18 compiler:</p>
<p><img alt="VTune Summary - Optimized ICC" src="../../_images/vtune_opt_intel.png" /></p>
<p>Notably, the optimized code utilizes the vector (AVX) units for 87% of
the total FP instructions with GCC, and for 94% of the FP instructions
with the Intel compiler. The capacity of the vector units is used in
85%-90%, which demonstrates that the code is almost fully vectorized.</p>
<p>Compared to the original code, the performance tests have shown that
on a Broadwell-based architecture the optimized code works from 2.5
times faster (RT solver) to 13 times faster (EOS solver) on a single
core. All optimizatoin techniques employed have been described in
detail in <a class="reference external" href="https://doi.org/10.5281/zenodo.2633704">the white paper</a>.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Sigma2/NRIS. Text shared under CC-BY 4.0 license.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>