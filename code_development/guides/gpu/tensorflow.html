

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Using TensorFlow in Python &mdash; Sigma2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css?v=a5c4661c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/nris.css?v=69e7a171" />
      <link rel="stylesheet" type="text/css" href="../../../_static/universal-navbar.css" />
      <link rel="stylesheet" type="text/css" href="../../../_static/statuspal.css" />

  
    <link rel="shortcut icon" href="../../../_static/nris.ico"/>
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://siteimproveanalytics.com/js/siteanalyze_6036825.js"></script>
      <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
      <script src="../../../_static/tabs.js?v=3030b3cb"></script>
      <script src="../../../_static/statuspal_widget.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">
<!-- Send url to parent when displayed as iframe -->
<script>
    const valid_orign_url = "https://www.sigma2.no"
    window.addEventListener('message', function(event) {
        if (event.data === 'getDocumentationIframeUrl' && event.origin.startsWith(valid_orign_url)) {
            // path only (/path/example.html)
            const path = window.location.pathname
            // query string (including the initial ? symbol)
            const search = window.location.search
            // Returns the hash (including the initial # symbol)
            const hash = window.location.hash
            const newUrl = path + search + hash;
            event.source.postMessage(newUrl, event.origin)
        }
    })

</script>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Sigma2/NRIS documentation
              <img src="../../../_static/NRIS Logo.svg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Policies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../code-of-conduct.html">Code of Conduct</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting help</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_help/support_line.html">Getting help</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_help/extended_support.html">Extended support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_help/faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_help/how_to_write_good_support_requests.html">Writing good support requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_help/qa-sessions.html">Open Question &amp; Answer Sessions for All Users</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_help/lost_forgotten_password.html">Lost, expiring or changing passwords</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_help/two_factor_authentication.html">One-time-pad (OTP) / Two-factor authentication</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.sigma2.no/project-leader-handbook">Project Leader Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../training/events.html">Training events</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training/notes_qa.html">Questions, Answers and Feedbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training/past_training.html">An overview over training events in the past</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training/videos.html">Training Video Archives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training/short_instructions.html">Short Instructions Video Archives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training/material.html">Training materials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/opslog.html">Status and maintenance of systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/applying_account.html">How do I get an account?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/applying_resources.html">Applying for computing and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/file_transfer.html">File transfer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/editing_files.html">Editing files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../vs_code/connect_to_server.html">Connecting to a system with Visual Studio Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/ssh.html">SSH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/ssh.html#common-ssh-errors">Common SSH errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/ood.html">Open OnDemand</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/R.html">First R calculation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Files, storage and backup</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../files_storage/nird_lmd.html">NIRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../files_storage/clusters.html">Storage areas on HPC clusters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../files_storage/quota.html">Storage quota</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../files_storage/backup.html">Backup on Betzy, Fram, Saga, and NIRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../files_storage/sharing_files.html">Data handling and storage policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../files_storage/performance.html">Optimizing storage performance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">HPC usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../hpc_machines/migration2metacenter.html">Migration to an NRIS HPC machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../computing/responsible-use.html">Using shared resources responsibly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../jobs/overview.html">Running jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../jobs/internet-login-compute-nodes.html">Login nodes:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../jobs/internet-login-compute-nodes.html#compute-nodes">Compute nodes:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../computing/tuning-applications.html">Tuning applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guides_llm.html">Running LLM Models in a Cluster Environment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Compute resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../hpc_machines/hardware_overview.html">Overview over our machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hpc_machines/betzy.html">Betzy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hpc_machines/fram.html">Fram</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hpc_machines/olivia.html">Olivia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hpc_machines/saga.html">Saga</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hpc_machines/lumi.html">LUMI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Software</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../software/modulescheme.html">Software module scheme</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../software/installed_software.html">Installed software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../software/userinstallsw.html">Installing software as user</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../software/appguides.html">Application guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../software/licenses.html">Licence and access policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../software/eessi.html">EESSI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Additional services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../nird_archive/sandbox-user-guide.html">NIRD Research Data Archive Sandbox (NIRD RDA sandbox)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nird_archive/user-guide.html">NIRD Research Data Archive (NIRD RDA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nird_toolkit/overview.html">NIRD Toolkit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nird_service_platform/overview_nird_service_platform.html">NIRD Service Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../services/easydmp-user-documentation.html">EasyDMP User Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_help/course_resources.html">CRaaS - Course Resources as a Service</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code development and tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../overview.html">Code development and tutorials</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Sigma2/NRIS documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Using TensorFlow in Python</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="using-tensorflow-in-python">
<h1>Using TensorFlow in Python<a class="headerlink" href="#using-tensorflow-in-python" title="Link to this heading"></a></h1>
<p>In this example we will try to utilize the
<code class="docutils literal notranslate"><span class="pre">TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0</span></code> library to execute a very simple
computation on the GPU. We could do the following interactively in Python, but
we will instead use a Slurm script, which will make it a bit more reproducible
and in some sense a bit easier, since we don’t have to sit and wait for the
interactive session to start.</p>
<p>We will use the following simple calculation in Python and <code class="docutils literal notranslate"><span class="pre">TensorFlow</span></code> to test
the GPUs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>

<span class="c1"># Test if there are any GPUs available</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Num GPUs Available: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)))</span>

<span class="c1"># Have Tensorflow output where computations are run</span>
<span class="n">tf</span><span class="o">.</span><span class="n">debugging</span><span class="o">.</span><span class="n">set_log_device_placement</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Create some tensors</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># Print result</span>
<span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
<p><a class="reference download internal" download="" href="../../../_downloads/26f47f6f96a83fe5d3ef564e0a754652/gpu_intro.py"><code class="xref download docutils literal notranslate"><span class="pre">gpu_intro.py</span></code></a></p>
<p>To run this we will first have to create a Slurm script in which we will request
resources. A good place to start is with a basic job
script (see <a class="reference internal" href="../../../jobs/job_scripts.html#job-scripts"><span class="std std-ref">Job Scripts</span></a>).
Use the following to create <code class="docutils literal notranslate"><span class="pre">submit_cpu.sh</span></code> (remember to substitute your project
number under <code class="docutils literal notranslate"><span class="pre">--account</span></code>):</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-U2FnYQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-0-U2FnYQ==" name="U2FnYQ==" role="tab" tabindex="0">Saga</button></div><div aria-labelledby="tab-0-U2FnYQ==" class="sphinx-tabs-panel group-tab" id="panel-0-U2FnYQ==" name="U2FnYQ==" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --job-name=TestGPUOnSaga</span>
<span class="c1">#SBATCH --account=nn&lt;XXXX&gt;k</span>
<span class="c1">#SBATCH --time=05:00</span>
<span class="c1">#SBATCH --mem-per-cpu=4G</span>
<span class="c1">#SBATCH --qos=devel</span>

<span class="c1">## Set up job environment:</span>
<span class="nb">set</span><span class="w"> </span>-o<span class="w"> </span>errexit<span class="w">  </span><span class="c1"># Exit the script on any error</span>
<span class="nb">set</span><span class="w"> </span>-o<span class="w"> </span>nounset<span class="w">  </span><span class="c1"># Treat any unset variables as an error</span>

module<span class="w"> </span>--quiet<span class="w"> </span>purge<span class="w">  </span><span class="c1"># Reset the modules to the system default</span>
module<span class="w"> </span>load<span class="w"> </span>TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0
module<span class="w"> </span>list

python<span class="w"> </span>gpu_intro.py
</pre></div>
</div>
<p><a class="reference download internal" download="" href="../../../_downloads/a10a1cbe5dff5f1d8ba3e7e366f27369/submit_cpu.sh"><code class="xref download docutils literal notranslate"><span class="pre">submit_cpu.sh</span></code></a></p>
</div></div>
<p>If we just run the above Slurm script with <code class="docutils literal notranslate"><span class="pre">sbatch</span> <span class="pre">submit_cpu.sh</span></code> the output
(found in the same directory as you executed the <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> command with a name
like <code class="docutils literal notranslate"><span class="pre">slurm-&lt;job-id&gt;.out</span></code>) will contain several errors as <code class="docutils literal notranslate"><span class="pre">Tensorflow</span></code> attempts
to communicate with the GPU, however, the program will still run and give the
following successful output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Num<span class="w"> </span>GPUs<span class="w"> </span>Available:<span class="w">  </span><span class="m">0</span><span class="w">                   </span>
tf.Tensor<span class="o">(</span><span class="w">                               </span>
<span class="o">[[</span><span class="m">22</span>.<span class="w"> </span><span class="m">28</span>.<span class="o">]</span><span class="w">                               </span>
<span class="w"> </span><span class="o">[</span><span class="m">49</span>.<span class="w"> </span><span class="m">64</span>.<span class="o">]]</span>,<span class="w"> </span><span class="nv">shape</span><span class="o">=(</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">)</span>,<span class="w"> </span><span class="nv">dtype</span><span class="o">=</span>float32<span class="o">)</span>
</pre></div>
</div>
<p>So the above, eventually, ran fine, but did not report any GPUs. The reason for
this is of course that we never asked for any GPUs in the first place. To remedy this we will include the <code class="docutils literal notranslate"><span class="pre">--gpus=1</span></code> in the Slurm script. We must also specify which partition we want to use (<code class="docutils literal notranslate"><span class="pre">--partition=accel</span></code> for P100 and <code class="docutils literal notranslate"><span class="pre">--partition=a100</span></code> for A100):</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-U2FnYSAoUDEwMCk=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-1-U2FnYSAoUDEwMCk=" name="U2FnYSAoUDEwMCk=" role="tab" tabindex="0">Saga (P100)</button><button aria-controls="panel-1-U2FnYSAoQTEwMCk=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-U2FnYSAoQTEwMCk=" name="U2FnYSAoQTEwMCk=" role="tab" tabindex="-1">Saga (A100)</button></div><div aria-labelledby="tab-1-U2FnYSAoUDEwMCk=" class="sphinx-tabs-panel group-tab" id="panel-1-U2FnYSAoUDEwMCk=" name="U2FnYSAoUDEwMCk=" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --job-name=TestGPUOnSaga</span>
<span class="c1">#SBATCH --account=nn&lt;XXXX&gt;k</span>
<span class="c1">#SBATCH --time=05:00</span>
<span class="c1">#SBATCH --mem-per-cpu=4G</span>
<span class="c1">#SBATCH --qos=devel</span>
<span class="hll"><span class="c1">#SBATCH --partition=accel</span>
</span><span class="hll"><span class="c1">#SBATCH --gpus=1</span>
</span>
<span class="c1">## Set up job environment:</span>
<span class="nb">set</span><span class="w"> </span>-o<span class="w"> </span>errexit<span class="w">  </span><span class="c1"># Exit the script on any error</span>
<span class="nb">set</span><span class="w"> </span>-o<span class="w"> </span>nounset<span class="w">  </span><span class="c1"># Treat any unset variables as an error</span>

module<span class="w"> </span>--quiet<span class="w"> </span>purge<span class="w">  </span><span class="c1"># Reset the modules to the system default</span>
module<span class="w"> </span>load<span class="w"> </span>TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0
module<span class="w"> </span>list

python<span class="w"> </span>gpu_intro.py
</pre></div>
</div>
<p><a class="reference download internal" download="" href="../../../_downloads/ed6198c78244a7ded352baab0657654f/submit_gpu.sh"><code class="xref download docutils literal notranslate"><span class="pre">submit_gpu.sh</span></code></a></p>
</div><div aria-labelledby="tab-1-U2FnYSAoQTEwMCk=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-U2FnYSAoQTEwMCk=" name="U2FnYSAoQTEwMCk=" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --job-name=TestGPUOnSaga</span>
<span class="c1">#SBATCH --account=nn&lt;XXXX&gt;k</span>
<span class="c1">#SBATCH --time=05:00</span>
<span class="c1">#SBATCH --mem-per-cpu=4G</span>
<span class="c1">#SBATCH --qos=devel</span>
<span class="hll"><span class="c1">#SBATCH --partition=a100</span>
</span><span class="hll"><span class="c1">#SBATCH --gpus=1</span>
</span>
<span class="c1">## Set up job environment:</span>
<span class="nb">set</span><span class="w"> </span>-o<span class="w"> </span>errexit<span class="w">  </span><span class="c1"># Exit the script on any error</span>
<span class="nb">set</span><span class="w"> </span>-o<span class="w"> </span>nounset<span class="w">  </span><span class="c1"># Treat any unset variables as an error</span>

<span class="hll">module<span class="w"> </span>--force<span class="w"> </span>swap<span class="w"> </span>StdEnv<span class="w"> </span>Zen2Env
</span>module<span class="w"> </span>--quiet<span class="w"> </span>purge<span class="w">  </span><span class="c1"># Reset the modules to the system default</span>
module<span class="w"> </span>load<span class="w"> </span>TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0

python<span class="w"> </span>gpu_intro.py
</pre></div>
</div>
<p><a class="reference download internal" download="" href="../../../_downloads/4a2b78ad2329aa36559991ea729cc2f1/submit_gpu_a100.sh"><code class="xref download docutils literal notranslate"><span class="pre">submit_gpu_a100.sh</span></code></a></p>
</div></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To use the A100 GPUs (second tab above) we must include <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">--force</span> <span class="pre">swap</span> <span class="pre">StdEnv</span> <span class="pre">Zen2Env</span></code>
(see <a class="reference internal" href="../../building_gpu.html#building-gpu"><span class="std std-ref">this page</span></a> for an explanation).</p>
</div>
<p>We should now see the following output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Num<span class="w"> </span>GPUs<span class="w"> </span>Available:<span class="w">  </span><span class="m">1</span><span class="w">                    </span>
tf.Tensor<span class="o">(</span><span class="w">                                </span>
<span class="o">[[</span><span class="m">22</span>.<span class="w"> </span><span class="m">28</span>.<span class="o">]</span><span class="w">                                </span>
<span class="w"> </span><span class="o">[</span><span class="m">49</span>.<span class="w"> </span><span class="m">64</span>.<span class="o">]]</span>,<span class="w"> </span><span class="nv">shape</span><span class="o">=(</span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">)</span>,<span class="w"> </span><span class="nv">dtype</span><span class="o">=</span>float32<span class="o">)</span><span class="w"> </span>
</pre></div>
</div>
<p>However, with complicated libraries such as <code class="docutils literal notranslate"><span class="pre">Tensorflow</span></code> we are still not
guaranteed that the above actually ran on the GPU. There is some output to
verify this, but we will check this manually as that can be applied more
generally.</p>
<section id="monitoring-the-gpus">
<h2>Monitoring the GPUs<a class="headerlink" href="#monitoring-the-gpus" title="Link to this heading"></a></h2>
<p>To do this monitoring we will start <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> before our job and let it run
while we use the GPU. We will change the <code class="docutils literal notranslate"><span class="pre">submit_gpu.sh</span></code> Slurm script above to
<code class="docutils literal notranslate"><span class="pre">submit_monitor.sh</span></code>, shown below:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-U2FnYQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-2-U2FnYQ==" name="U2FnYQ==" role="tab" tabindex="0">Saga</button></div><div aria-labelledby="tab-2-U2FnYQ==" class="sphinx-tabs-panel group-tab" id="panel-2-U2FnYQ==" name="U2FnYQ==" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --job-name=TestGPUOnSaga</span>
<span class="c1">#SBATCH --account=nn&lt;XXXX&gt;k</span>
<span class="c1">#SBATCH --time=05:00</span>
<span class="c1">#SBATCH --mem-per-cpu=4G</span>
<span class="c1">#SBATCH --qos=devel</span>
<span class="c1">#SBATCH --partition=accel</span>
<span class="c1">#SBATCH --gpus=1</span>

<span class="c1">## Set up job environment:</span>
<span class="nb">set</span><span class="w"> </span>-o<span class="w"> </span>errexit<span class="w">  </span><span class="c1"># Exit the script on any error</span>
<span class="nb">set</span><span class="w"> </span>-o<span class="w"> </span>nounset<span class="w">  </span><span class="c1"># Treat any unset variables as an error</span>

module<span class="w"> </span>--quiet<span class="w"> </span>purge<span class="w">  </span><span class="c1"># Reset the modules to the system default</span>
module<span class="w"> </span>load<span class="w"> </span>TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0
module<span class="w"> </span>list

<span class="c1"># Setup monitoring</span>
<span class="hll">nvidia-smi<span class="w"> </span>--query-gpu<span class="o">=</span>timestamp,utilization.gpu,utilization.memory<span class="w"> </span><span class="se">\</span>
</span><span class="hll"><span class="w">	</span>--format<span class="o">=</span>csv<span class="w"> </span>--loop<span class="o">=</span><span class="m">1</span><span class="w"> </span>&gt;<span class="w"> </span><span class="s2">&quot;gpu_util-</span><span class="nv">$SLURM_JOB_ID</span><span class="s2">.csv&quot;</span><span class="w"> </span><span class="p">&amp;</span>
</span><span class="hll"><span class="nv">NVIDIA_MONITOR_PID</span><span class="o">=</span><span class="nv">$!</span><span class="w">  </span><span class="c1"># Capture PID of monitoring process</span>
</span><span class="c1"># Run our computation</span>
python<span class="w"> </span>gpu_intro.py
<span class="c1"># After computation stop monitoring</span>
<span class="hll"><span class="nb">kill</span><span class="w"> </span>-SIGINT<span class="w"> </span><span class="s2">&quot;</span><span class="nv">$NVIDIA_MONITOR_PID</span><span class="s2">&quot;</span>
</span></pre></div>
</div>
<p><a class="reference download internal" download="" href="../../../_downloads/66ff041b4ef0bd31a54dc7cd77155bdc/submit_monitor.sh"><code class="xref download docutils literal notranslate"><span class="pre">submit_monitor.sh</span></code></a></p>
</div></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The query used to monitor the GPU can be further extended by adding additional
parameters to the <code class="docutils literal notranslate"><span class="pre">--query-gpu</span></code> flag. Check available options
<a class="reference external" href="https://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf">here</a>.</p>
</div>
<p>Run this script with <code class="docutils literal notranslate"><span class="pre">sbatch</span> <span class="pre">submit_monitor.sh</span></code> to test if the output
<code class="docutils literal notranslate"><span class="pre">gpu_util-&lt;job</span> <span class="pre">id&gt;.csv</span></code> actually contains some data. We can then use this data
to ensure that we are actually using the GPU as intended. Pay specific attention
to <code class="docutils literal notranslate"><span class="pre">utilization.gpu</span></code> which shows the percentage of how much processing the GPU
is doing. It is not expected that this will always be <code class="docutils literal notranslate"><span class="pre">100%</span></code> as we will need to
transfer data, but the average should be quite high.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Sigma2/NRIS. Text shared under CC-BY 4.0 license.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>