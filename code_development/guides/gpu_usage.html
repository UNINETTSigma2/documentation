

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Basic commands for GPU-usage &mdash; Sigma2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/tabs.css?v=a5c4661c" />
      <link rel="stylesheet" type="text/css" href="../../_static/nris.css?v=69e7a171" />
      <link rel="stylesheet" type="text/css" href="../../_static/universal-navbar.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/statuspal.css" />

  
    <link rel="shortcut icon" href="../../_static/nris.ico"/>
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=f281be69"></script>
      <script async="async" src="https://siteimproveanalytics.com/js/siteanalyze_6036825.js"></script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script src="../../_static/tabs.js?v=3030b3cb"></script>
      <script src="../../_static/statuspal_widget.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">
<!-- Send url to parent when displayed as iframe -->
<script>
    const valid_orign_url = "https://www.sigma2.no"
    window.addEventListener('message', function(event) {
        if (event.data === 'getDocumentationIframeUrl' && event.origin.startsWith(valid_orign_url)) {
            // path only (/path/example.html)
            const path = window.location.pathname
            // query string (including the initial ? symbol)
            const search = window.location.search
            // Returns the hash (including the initial # symbol)
            const hash = window.location.hash
            const newUrl = path + search + hash;
            event.source.postMessage(newUrl, event.origin)
        }
    })

</script>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Sigma2/NRIS documentation
              <img src="../../_static/NRIS Logo.svg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Policies</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../code-of-conduct.html">Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.sigma2.no/acceptable-use-policy">User Policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/security-policy.html">Security policy for Sigma2 infrastructure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/sharing_files.html">Data handling and storage policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/licenses.html">Licence and access policies</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.sigma2.no/data-policy">Data Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.sigma2.no/data-decommissioning-policies">Data decommissioning policies</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.sigma2.no/central-data-library-policy">Central Data Library Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.sigma2.no/policies">Overview of Sigma2 Policies</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting help</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/support_line.html">Getting help</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/extended_support.html">Extended support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/how_to_write_good_support_requests.html">Writing good support requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/qa-sessions.html">Open Question &amp; Answer Sessions for All Users</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/lost_forgotten_password.html">Lost, expiring or changing passwords</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/two_factor_authentication.html">One-time-pad (OTP) / Two-factor authentication</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.sigma2.no/project-leader-handbook">Project Leader Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../training/events.html">Training events</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/notes_qa.html">Questions, Answers and Feedbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/videos.html">Training Video Archives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/short_instructions.html">Short Instructions Video Archives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/material.html">Training materials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/opslog.html">Status and maintenance of systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/applying_account.html">How do I get an account?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/applying_resources.html">Applying for computing and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/file_transfer.html">File transfer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/editing_files.html">Editing files</a></li>
<li class="toctree-l1"><a class="reference internal" href="vs_code/connect_to_server.html">Connecting to a system with Visual Studio Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/ssh.html">SSH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/ssh.html#common-ssh-errors">Common SSH errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/ood.html">Open OnDemand</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/R.html">First R calculation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data and Storage Services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/nird/nird_dp.html">NIRD Data Peak</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/nird/nird_dl.html">NIRD Data Lake</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/nird/backup_lmd.html">NIRD Backup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/nird/cdl.html">(NIRD) Central Data Library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nird_archive/user-guide.html">NIRD Research Data Archive (NIRD RDA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nird_service_platform/overview_nird_service_platform.html">NIRD Service Platform</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Storage Resources and Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/nird_lmd.html">NIRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/clusters.html">Storage areas on HPC clusters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/quota.html">Storage quota</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/backup.html">Backup on Betzy, Saga, and NIRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/performance.html">Optimizing storage performance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">HPC usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/migration2metacenter.html">Migration to an NRIS HPC machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../computing/responsible-use.html">Using shared resources responsibly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/overview.html">Running jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/internet-login-compute-nodes.html">Login nodes:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/internet-login-compute-nodes.html#compute-nodes">Compute nodes:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../computing/tuning-applications.html">Tuning applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides_llm.html">Running LLM Models in a Cluster Environment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Compute resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/hardware_overview.html">Overview over our machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/betzy.html">Betzy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/olivia.html">Olivia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/saga.html">Saga</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/lumi.html">LUMI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Software</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../software/modulescheme.html">Software module scheme</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/installed_software.html">Installed software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/userinstallsw.html">Installing software as user</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/appguides.html">Application guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/eessi.html">EESSI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tools and Additional services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../nird_toolkit/overview.html">NIRD Toolkit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/course_resources.html">CRaaS - Course Resources as a Service</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code development and tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Code development and tutorials</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Sigma2/NRIS documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Basic commands for GPU-usage</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="basic-commands-for-gpu-usage">
<span id="gpuusage"></span><h1><a class="toc-backref" href="#id1" role="doc-backlink">Basic commands for GPU-usage</a><a class="headerlink" href="#basic-commands-for-gpu-usage" title="Link to this heading"></a></h1>
<p>We present some basic command-lines that provide statistics about GPU utilization. A special focus here will be the commands <a class="reference external" href="https://developer.nvidia.com/nvidia-system-management-interface"><code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></a> and <a class="reference external" href="https://sep5.readthedocs.io/en/latest/ROCm_System_Managment/ROCm-System-Managment.html"><code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code></a>, which can be used for monitoring GPU devices on heterogenous systems involving CPUs and GPUs. This guide is motivated by the increase use of software with GPU support, and in which the access to GPU usage is not often trivial. It thus represents an initial step towards improving the utilization of GPUs.</p>
<p>This guide should be useful for users who are running GPU-based applications. By the end of this guide, users will learn about:</p>
<ul class="simple">
<li><p>How to run <a class="reference external" href="https://developer.nvidia.com/nvidia-system-management-interface"><code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></a> and <a class="reference external" href="https://sep5.readthedocs.io/en/latest/ROCm_System_Managment/ROCm-System-Managment.html"><code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code></a> commands on HPC systems.</p></li>
<li><p>How to access specific information related to hardware and software; in particular:</p>
<ul>
<li><p>GPU and memory utilizations</p></li>
<li><p>Device statistics</p></li>
<li><p>Device monitoring</p></li>
<li><p>Device topology</p></li>
</ul>
</li>
</ul>
<nav class="contents" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#basic-commands-for-gpu-usage" id="id1">Basic commands for GPU-usage</a></p>
<ul>
<li><p><a class="reference internal" href="#how-to-run-nvidia-smi-and-rocm-smi-commands" id="id2">How to run <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> and <code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code> commands</a></p></li>
<li><p><a class="reference internal" href="#command-nvidia-smi" id="id3">Command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></a></p></li>
<li><p><a class="reference internal" href="#command-rocm-smi" id="id4">Command <code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#conclusion" id="id5">Conclusion</a></p></li>
<li><p><a class="reference internal" href="#relevant-links" id="id6">Relevant links</a></p></li>
</ul>
</nav>
<section id="how-to-run-nvidia-smi-and-rocm-smi-commands">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">How to run <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> and <code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code> commands</a><a class="headerlink" href="#how-to-run-nvidia-smi-and-rocm-smi-commands" title="Link to this heading"></a></h2>
<p>The commands <a class="reference external" href="https://developer.nvidia.com/nvidia-system-management-interface"><code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></a> and <a class="reference external" href="https://sep5.readthedocs.io/en/latest/ROCm_System_Managment/ROCm-System-Managment.html"><code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code></a> are used in general to monitor and manage GPU applications; and they will be discussed here in the context of HPC systems. These commands should be launched while a submitted application is running. This is necessary in order to collect real-time activities of GPU utilization and memory usage among other metrics. These commands can also be used to access information about GPU-based systems (NVIDIA and AMD), regardless of whether GPU applications are running or not. In the following we present two ways how to run these commands:</p>
<p>The command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> is available from an NVIDIA GPU node, and can be accessed in <a class="reference internal" href="../../hpc_machines/hardware_overview.html#hardware-overview"><span class="std std-ref">NRIS clusters</span></a> by following these steps:</p>
<ul class="simple">
<li><p>Submit a job:                <code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">sbatch</span> <span class="pre">job.slurm</span> </code></p></li>
<li><p>Display which node:          <code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">squeue</span> <span class="pre">–-me</span> </code></p></li>
<li><p>Ssh to the listed node e.g.  <code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">ssh</span> <span class="pre">c7-8</span></code> on Saga and <code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">ssh</span> <span class="pre">b5304</span></code> on Betzy.</p></li>
<li><p>Run the command:             <code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">nvidia-smi</span></code></p></li>
<li><p>For more options:            <code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">nvidia-smi</span> <span class="pre">-h</span></code></p></li>
</ul>
<p>Information about GPU nodes can be displayed via the command <code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">sinfo</span> <span class="pre">–p</span> <span class="pre">[name-of-partition]</span></code>. In <a class="reference internal" href="../../hpc_machines/hardware_overview.html#hardware-overview"><span class="std std-ref">NRIS clusters</span></a>, the partition is specified by  <code class="docutils literal notranslate"><span class="pre">accel</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that access to a GPU node without having active jobs will be denied and will result in <em>Authentication failed</em>.</p>
</div>
<p>The command-lines defined above are also valid on an AMD GPU node, in which SLURM is used as a workload manager. Here <code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code> will be used instead.</p>
<p>An alternative to the first method, is to run the commands <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> and <code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code> interactively, as described below. This interactive way permits displaying GPU usage in real-time.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-bnZpZGlhLXNtaQ==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-0-bnZpZGlhLXNtaQ==" name="bnZpZGlhLXNtaQ==" role="tab" tabindex="0">nvidia-smi</button><button aria-controls="panel-0-cm9jbS1zbWk=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-cm9jbS1zbWk=" name="cm9jbS1zbWk=" role="tab" tabindex="-1">rocm-smi</button></div><div aria-labelledby="tab-0-bnZpZGlhLXNtaQ==" class="sphinx-tabs-panel group-tab" id="panel-0-bnZpZGlhLXNtaQ==" name="bnZpZGlhLXNtaQ==" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="k">for</span><span class="w"> </span>j<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="o">{</span><span class="m">1</span>..10<span class="o">}</span><span class="p">;</span><span class="w"> </span><span class="k">do</span><span class="w"> </span>srun<span class="w"> </span>--jobid<span class="o">=</span>JobID<span class="w"> </span>--interactive<span class="w"> </span>--pty<span class="w"> </span>nvidia-smi<span class="p">;</span><span class="w"> </span>sleep<span class="w"> </span><span class="m">2</span><span class="p">;</span><span class="w"> </span><span class="k">done</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-cm9jbS1zbWk=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-cm9jbS1zbWk=" name="cm9jbS1zbWk=" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="k">for</span><span class="w"> </span>j<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="o">{</span><span class="m">1</span>..10<span class="o">}</span><span class="p">;</span><span class="w"> </span><span class="k">do</span><span class="w"> </span>srun<span class="w"> </span>--jobid<span class="o">=</span>JobID<span class="w"> </span>--interactive<span class="w"> </span>--pty<span class="w"> </span>rocm-smi<span class="p">;</span><span class="w"> </span>sleep<span class="w"> </span><span class="m">2</span><span class="p">;</span><span class="w"> </span><span class="k">done</span>
</pre></div>
</div>
</div></div>
<p>where the <em>JobID</em> needs to be specified. In this example, the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code>/<code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code> runs for 10 times as defined by the range {1..10}, in which each run is delayed with 2 seconds, as defined by the option <code class="docutils literal notranslate"><span class="pre">sleep</span> <span class="pre">2</span></code>. Here additional options can be specified in this syntax to display selective metrics as described in the next section.</p>
</section>
<section id="command-nvidia-smi">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></a><a class="headerlink" href="#command-nvidia-smi" title="Link to this heading"></a></h2>
<p>The command utility <a class="reference external" href="https://developer.nvidia.com/nvidia-system-management-interface"><code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></a> is provided by NVIDIA and stands for “NVIDIA System Management Interface”. As the name indicates, the tool is useful for monitoring and managing GPU applications.</p>
<p>In this section, we cover the following <a class="reference external" href="https://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf">options</a>:</p>
<ul class="simple">
<li><p>Overview of GPU usage</p></li>
<li><p>Device statistics</p></li>
<li><p>Device monitoring</p></li>
<li><p>Device topology</p></li>
</ul>
<p>In particular, we show how to display certain statistical information based on the <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> command and other related <a class="reference external" href="https://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf">options</a>.</p>
<section id="overview-of-gpu-usage">
<h3>Overview of GPU usage<a class="headerlink" href="#overview-of-gpu-usage" title="Link to this heading"></a></h3>
<p>The command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> provides a general overview of GPU usage. The output of the command is shown in <em>Fig. 1</em>. The figure contains two tables: The first one provides information about available GPUs and additional technical information related to the hardware, while the 2nd one contains information about different processes running on GPU. We summarize this information in the <em>Table 1.</em>. Here among other information displayed are the driver and cuda versions, the GPU name, memory and GPU utilization. These last two metrics indicate well-utilization of GPUs. The example displayed in <em>Table. 1</em> (also <em>Fig. 1.</em>) shows that the running application uses 325 MiB of memory (the GPU-device memory is ~16 GiB) and 39% of GPU. Note that the percent refers to the percent of time in the past sampling period, when one or more kernels were executed on the GPU.</p>
<p>In the following we present additional options to complement the information provided by the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code>. Such options allow displaying selective information.</p>
<div align="center">
<p><img alt="Fig1" src="../../_images/fig1.png" /></p>
<p><strong>Fig. 1.</strong> <em>Overview of GPU usage in a NVIDIA’s system - Output from the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code>.</em></p>
</div>
<div align="center">
<p><img alt="Fig2" src="../../_images/fig2.png" /></p>
<p><strong>Table 1.</strong> <em>Description of GPU usage metrics extracted from Fig. 1 (see <a class="reference external" href="https://medium.com/analytics-vidhya/explained-output-of-nvidia-smi-utility-fc4fbee3b124">here</a> for more details).</em></p>
</div>
</section>
<section id="device-statistics">
<h3>Device statistics<a class="headerlink" href="#device-statistics" title="Link to this heading"></a></h3>
<p>Displaying statistics of a device is provided by the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">stats</span></code>. In particular, one can specify additional options to select statistics about GPU utilization (left-hand side) and/or memory utilization (right-hand side), as shown in <em>Fig. 2</em>. This is provided by the commands <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">stats</span> <span class="pre">-d</span> <span class="pre">gpuUtil</span></code> and <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">stats</span> <span class="pre">-d</span> <span class="pre">memUtil</span></code> respectively. The output of the commands is shown in <em>Fig.2</em>. Here the first column indicates the GPU index and the second one displays either the GPU or memory utilization, while the last column indicates the percent of time of either the GPU or memory utilization. More information can be displayed by the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">stats</span> <span class="pre">-h</span></code>.</p>
<div align="center">
<p><img alt="Fig3" src="../../_images/fig3.png" /></p>
<p><strong>Fig. 2.</strong> <em>Device statistics - Output generated from the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">stats</span> <span class="pre">-d</span> <span class="pre">gpuUtil</span></code> (left-hand side) and <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">stats</span> <span class="pre">-d</span> <span class="pre">memUtil</span></code> (right-hand side).</em></p>
</div>
</section>
<section id="device-monitoring">
<h3>Device monitoring<a class="headerlink" href="#device-monitoring" title="Link to this heading"></a></h3>
<p>The device monitoring option provides additional metrics about a GPU-device; in particular, SM (Streaming Multiprocessor) utilization, memory utilization, temperature, power consumption, memory clock rate (mclk), processor clock rate (pclk) (see <em>Fig. 3.</em>). This information is provided by the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">dmon</span></code>. Here one can also specify additional options to select desired metrics: e.g. the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">pmon</span> <span class="pre">-s</span> <span class="pre">u</span></code> displays the GPU utilization together with other metrics mentioned above, while the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">pmon</span> <span class="pre">-s</span> <span class="pre">m</span></code> displays the memory utilization combined with various metrics.</p>
<div align="center">
<p><img alt="Fig4" src="../../_images/fig4.png" /></p>
<p><strong>Fig. 3.</strong> <em>Device monitoring - Output generated from the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">dmon</span></code>.</em></p>
</div>
</section>
<section id="device-topology">
<h3>Device topology<a class="headerlink" href="#device-topology" title="Link to this heading"></a></h3>
<p>The device topology option provides information about the nature of interconnect, in particular, in GPU-GPU and GPU-mlx5 (mlx5 refers to <a class="reference external" href="https://docs.nvidia.com/networking/display/MLNXOFEDv451010/Introduction">Mellanox ConnectX-5</a>) networks as well as CPU affinity and NUMA (Non-Uniform Memory Access) affinity in an HPC system architecture. This is provided by the command-line <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">topo</span> <span class="pre">-m</span></code>, and is useful for optimizing GPU applications that run on multiple GPUs. The output of the command is shown in <em>Fig. 4</em>. Here the figure represents a matrix composed of four GPU devices (GPU0, GPU1, GPU2 and GPU3) and two Mellanox devices (mlx5_0, mlx5_1), in which each pair is connected via different type of interconnects. In particular, GPUs are interconnected via <a class="reference external" href="https://www.nvidia.com/en-us/data-center/nvlink/">NVLink</a>, which allows high-bandwidth communication between GPUs. The NVLink in NVIDIA A100, which is displayed in <em>Fig. 4.</em> is the third generation NVLink, and is expected to provide higher performance compared to the first and second generations i.e. P100 and V100, respectively. On the other hand, the interconnect between a GPU and mlx5 is established either through SYS (e.g. GPU0-mlx5_0) or PIX (e.g. GPU1-mlx5_0) connections (see Legend in <em>Fig. 4</em>).</p>
<p>In short, understanding the device topology is useful for ensuring the functionality of, for instance, the <a class="reference external" href="https://docs.nvidia.com/cuda/gpudirect-rdma/#:~:text=GPUDirect%20RDMA%20is%20a%20technology,video%20acquisition%20devices%2C%20storage%20adapters.">GPUDirect RDMA</a> (Remote Direct Memory Access) communication. The RDMA technology permits direct data transfer between a GPU and a third party device (e.g. network interface cards - NICs) through the PCIe (Peripheral Component Interconnect Express) bus and without passing by the CPU host, thus resulting in higher speed data transfer and lower latency.</p>
<div align="center">
<p><img alt="Fig5" src="../../_images/fig5.png" /></p>
<p><strong>Fig. 4.</strong> <em>Device topology - Output generated from the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">topo</span> <span class="pre">-m</span></code>.</em></p>
</div>
<p>For completeness, we provide the command <code class="docutils literal notranslate"><span class="pre">lscpu</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">NUMA</span></code>, which lists NUMA nodes. The output of this command e.g. from the node <code class="docutils literal notranslate"><span class="pre">b5301</span></code> in our cluster <a class="reference internal" href="../../hpc_machines/betzy.html#betzy"><span class="std std-ref">Betzy</span></a> is</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">NUMA node(s):          8</span>
<span class="go">NUMA node0 CPU(s):     0-7,64-71</span>
<span class="go">NUMA node1 CPU(s):     8-15,72-79</span>
<span class="go">NUMA node2 CPU(s):     16-23,80-87</span>
<span class="go">NUMA node3 CPU(s):     24-31,88-95</span>
<span class="go">NUMA node4 CPU(s):     32-39,96-103</span>
<span class="go">NUMA node5 CPU(s):     40-47,104-111</span>
<span class="go">NUMA node6 CPU(s):     48-55,112-119</span>
<span class="go">NUMA node7 CPU(s):     56-63,120-127</span>
</pre></div>
</div>
<p>Additional options that can be combined with the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> are summarized in the <em>Table. 2</em> (see <a class="reference external" href="https://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf">here</a> for more details), and can also be displayed using the command <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">topo</span> <span class="pre">-h</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Options</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>nvidia-smi topo</p></td>
<td><p>Display topological information about the system</p></td>
</tr>
<tr class="row-odd"><td><p>nvidia-smi topo –matrix</p></td>
<td><p>Display the GPUDirect communication matrix for the system</p></td>
</tr>
<tr class="row-even"><td><p>nvidia-smi topo –cpu</p></td>
<td><p>CPU number for which to display all GPUs with an affinity</p></td>
</tr>
<tr class="row-odd"><td><p>nvidia-smi topo –matrix_pci</p></td>
<td><p>Display the GPUDirect communication matrix for the system (PCI Only)</p></td>
</tr>
</tbody>
</table>
<p><strong>Table. 2</strong> <em>Various options that can be combined with the command <a class="reference external" href="https://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf"><code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">topo</span></code></a> to display specific metrics related to the topology of the used system.</em></p>
</section>
</section>
<section id="command-rocm-smi">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Command <code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code></a><a class="headerlink" href="#command-rocm-smi" title="Link to this heading"></a></h2>
<p>The command-line <a class="reference external" href="https://sep5.readthedocs.io/en/latest/ROCm_System_Managment/ROCm-System-Managment.html"><code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code></a> is the counterpart of the NVIDIA’s <a class="reference external" href="https://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf"><code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></a> tool and is provided by AMD as part of the <a class="reference external" href="https://sep5.readthedocs.io/en/latest/ROCm_System_Managment/ROCm-System-Managment.html">ROCm</a> software stack. The command can be used in the same way as the <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> command for displaying various metrics.</p>
<p>The command <a class="reference external" href="https://sep5.readthedocs.io/en/latest/ROCm_System_Managment/ROCm-System-Managment.html"><code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code></a> can be combined with specific options to display more technical information. A summary of selective options is provided in the <em>Table. 3</em>. We refer readers to the <a class="reference external" href="https://sep5.readthedocs.io/en/latest/ROCm_System_Managment/ROCm-System-Managment.html">ROCm</a> documentation for further details.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Options</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>–showhw</p></td>
<td><p>Display details of hardware</p></td>
</tr>
<tr class="row-odd"><td><p>-u, –showuse</p></td>
<td><p>Display GPU utilization</p></td>
</tr>
<tr class="row-even"><td><p>–showmemuse</p></td>
<td><p>Display GPU memory utilization</p></td>
</tr>
<tr class="row-odd"><td><p>-b, –showbw</p></td>
<td><p>Display estimated PCIe use</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>(i.e. estimated number of bytes sent and received by a GPU through the PCIe bus)</p></td>
</tr>
<tr class="row-odd"><td><p>–showtoponuma</p></td>
<td><p>Display device topology including NUMA nodes</p></td>
</tr>
<tr class="row-even"><td><p>-P, –showpower</p></td>
<td><p>Display current Average Graphics Package Power Consumption</p></td>
</tr>
<tr class="row-odd"><td><p>-t, –showtemp</p></td>
<td><p>Display current temperature</p></td>
</tr>
<tr class="row-even"><td><p>-g, –showgpuclocks</p></td>
<td><p>Display current GPU clock frequencies</p></td>
</tr>
</tbody>
</table>
<p><strong>Table. 3</strong> <em>Various options that can be combined with the command <a class="reference external" href="https://sep5.readthedocs.io/en/latest/ROCm_System_Managment/ROCm-System-Managment.html"><code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code></a> to display specific metrics.</em></p>
</section>
</section>
<section id="conclusion">
<h1><a class="toc-backref" href="#id5" role="doc-backlink">Conclusion</a><a class="headerlink" href="#conclusion" title="Link to this heading"></a></h1>
<p>In conclusion, we have presented an overview of the command-lines <a class="reference external" href="https://developer.nvidia.com/nvidia-system-management-interface"><code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></a> and <a class="reference external" href="https://sep5.readthedocs.io/en/latest/ROCm_System_Managment/ROCm-System-Managment.html"><code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code></a> for monitoring and managing GPU-based applications. In addition, we have presented various options that can be combined with these commands to display specific metrics. We have also shown how to run them interactively in a cluster.</p>
<p>Overall, these commands are useful for revealing information, in particular, about the GPU and memory utilizations, which are a key indicator of how well the GPUs are utilized. Additional options can be specified such as the GPU-device topology option, which provides an overview of different interconnects between GPUs and Mellanox devices as well as CPU and NUMA affinities. Displaying such information helps improving the performance. Although the <a class="reference external" href="https://developer.nvidia.com/nvidia-system-management-interface"><code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code></a> and <a class="reference external" href="https://sep5.readthedocs.io/en/latest/ROCm_System_Managment/ROCm-System-Managment.html"><code class="docutils literal notranslate"><span class="pre">rocm-smi</span></code></a> commands provide real-time metrics, their use is limited to being a statistical indicator of GPU usage. Therefore more advanced techniques are needed in order to identify bottlenecks in GPU applications. Here code profiling becomes a necessity to help optimizing performance and to ensure well-utilization of GPUs.</p>
</section>
<section id="relevant-links">
<h1><a class="toc-backref" href="#id6" role="doc-backlink">Relevant links</a><a class="headerlink" href="#relevant-links" title="Link to this heading"></a></h1>
<p><a class="reference external" href="https://developer.nvidia.com/nvidia-system-management-interface">NVIDIA-SMI</a> (see also <a class="reference external" href="https://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf">here</a>)</p>
<p><a class="reference external" href="https://sep5.readthedocs.io/en/latest/ROCm_System_Managment/ROCm-System-Managment.html">ROCm-SMI</a></p>
<p><a class="reference external" href="https://www.nvidia.com/en-us/data-center/nvlink/">NVLink</a></p>
<p><a class="reference external" href="https://docs.nvidia.com/networking/display/MLNXOFEDv451010/Introduction">NVIDIA Mellanox device</a></p>
<p><a class="reference external" href="https://www.nvidia.com/en-us/networking/">NVIDIA networking</a></p>
<p><a class="reference external" href="https://docs.nvidia.com/cuda/gpudirect-rdma/#:~:text=GPUDirect%20RDMA%20is%20a%20technology,video%20acquisition%20devices%2C%20storage%20adapters.">GPUDirect RDMA</a></p>
<p><a class="reference external" href="https://docs.amd.com/api/khub/documents/4RRmDJWYi97s96NIjwC~JQ/content">Network on AMD</a></p>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2026, Sigma2/NRIS. Text shared under CC-BY 4.0 license.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>